% !TEX root = ../entropy.tex

\section{Spending profiles predict emergency savings}%
\label{sec:results}

Table~\ref{tab:reg_has_inflows_main} shows the effect of entropy on the
probability of building emergency savings in a given month. Columns (1)-(3)
show results for unsmoothed entropy based on 9 categories, 48 categories, and
merchant names, respectively. Columns (4)-(6) results for smoothed entropy
based on the same variables. All models include user and year-month fixed
effects, and standard errors are clustered at the user-level. 95\% confidence
intervals are shown in brakets.

\input{\tabdir/reg_has_inflows_main.tex}

Results for unsmoothed entropy suggest that a one unit increase in entropy is
associated with an increase in the probability of a user making at least one
transfer into their savings accounts of between 1.5 and 2.7 percentage points
-- an effect up to two times larger than that of a \pounds1000 increase in
monthly income. Conversely, the effect for unsmooth entropy is smaller in
magnitude but runs in the reverse direction: a one-unit increase in the
smoothed entropy score is associated with a reduction in the probability of
transferring money into savings account of between 0.4 and 1.6 percentage
points -- an effect that, in absolute magnitude, is about equal to that of a
\pounds1000 increase in monthly income.

As discussed in Section~\ref{sub:estimation}, these results are not a results
of reverse causality. While we might think that making a savings transactions
might change some or all of the components of entropy discussed in
Section~\ref{sub:spending_profiles} -- the number of unique spending categories
with positive frequency count, the standard deviation of these counts, and the
total number of spend transactions -- and thus change entropy, this is not the
case because of the way we define entropy and savings, and the way spending
transactions are categorised. We define entropy based on all current account
debits that are identified as spends, while we define savings transactions as
the sum of all savings accounts credits. If a user transfers money from their
current account to their savings account, this will be identified as a savings
transaction, but be identified as a transfer on their current account and thus
not considered when calculating their entropy score.

Overall, the effect of entropy in spending profiles is statistically and
economically significant, and robust across different definitions. In other
words, the scores seem to pick up a feature of the spending distribution that
is predictive of savings behaviour.

\edit{Two questions remain: first, how can we interpret the aspect of spending
distributions that entropy captures and that is related to savings behaviour?
Second, why does smoothing entropy scores flip the direction of the effec? We
will address these in turn.}


\subsection{Why does smoothing flip the direction of the effect}%
\label{sub:why_does_smoothing_flip_the_direction_of_the_effect}

As discussed in Section~\ref{sub:spending_profiles}, we create smooth entropy
measures by additively smoothing the probabilities that a user makes a
transaction in a particular spending category at a particular point in time. To
do this, we add one to the frequency count of that spending category in the
numerator and add the total number of spend categories to the total number of
spend transactions in the denominator.

While we have just seen above that entropy captures more about users' spending
profile than any of its three component parts, to understand the effect of
smoothing on entropy scores it is still instructive to see how smoothing
affects entropy scores as a function of the three components.
Figure~\ref{fig:effect_of_smoothing} shows the effect of smoothing on entropy
(top left) and entropy as a function of the number of unique spend categories
with positive frequency count (top right), the standard deviation of these
counts (bottom left), and the total number of spend transactions (bottom
right).

\newpage

\begin{equation}
\label{equ:entropy_us}
H = -\sum_{c \in \setcp}{\left(\frac{f_c}{F}\right)
log\left(\frac{f_c}{F}\right)},
\end{equation}

\begin{equation}
\label{equ:entropy_s}
H^s = -\sum_{c \in \setcp}{\left(\frac{f_c + 1}{F + |\setc|}\right)
log\left(\frac{f_c + 1}{F + |\setc|}\right)}
- |\setcz|\left(\frac{1}{F + |\setc|}\right)
log\left(\frac{1}{F + |\setc|}\right),
\end{equation}

\input{\tabdir/reg_comp_only.tex}

\begin{figure}[h]
    \centering 
    \caption{Effect of smoothing on entropy}
    \label{fig:effect_of_smoothing}
    \includegraphics[width=.49\textwidth]{\figdir/smoothed_unsmoothed_corr.png}
    \includegraphics[width=.49\textwidth]{\figdir/smoothing_on_nunique_tag_spend.png}
    \includegraphics[width=.49\textwidth]{\figdir/smoothing_on_std_tag_spend.png}
    \includegraphics[width=.49\textwidth]{\figdir/smoothing_on_txns_count_spend.png}
    % \fignote{\textwidth}{Effect of smoothing on entropy (top left) and entropy
    %     as a function of its three main components: the number of spending
    %     categories with positive frequency-counts (top right), the standard
    %     deviatioin of these counts (lower left), and the total number of
    % spending transaction (lower right). Value ranges for entropy components are
% trimmed at the 95th percentile.}
\end{figure}


\newpage


% Negative sign in 4 makes sense: since increading f_c moves fraction closer to
% one, moves log closer to zero, hence, H^s increases more if c added to rhs of
% expression.

The two salient facts from the top left panel are that unsmoothed and smoothed
entropy are positively correlated, and that the variance of smoothed entropy
scores for any given level of unsmoothed entropy decreases as unsmoothed
entropy gets larger.

This makes sense: correlates positively becuase first part of smoothed entropy
is almost equal to unsmoothed entropy. Higher variance for lower levels of
unsmoothed entropy because it is low if there are many spend categories with zero
counts, which do not enter the sum. However, in smoothed entropy, all these
categories contribute to the constant part on the right hand side. Depending on
other elements of the distribution, this creates a high or low smoothed entropy
score.

Sign reversal due to some people with low entropy scores that get turned into
high entropy people.

% Look at dev figure: wrap by nunique_tag, colour by F and std to see how they
% help


\subsection{How can we interpret entropy?}%
\label{sub:is_entropy_more_than_the_sum_of_its_parts_}

One possibility is that spending entropy is related to savings behaviour
through some or all of its main components we discussed in
Section~\ref{sub:spending_profiles}: the number of unqiue spending categories
with a positive frequency count, the standard deviation of those counts, and
the number of spending transactions. Here we want to test whether entropy
remains predictive of savings behaviour once we control for these components.

\input{\tabdir/reg_has_inflows_comp.tex}

Columns (1) and (3) in Table~\ref{tab:reg_has_inflows_comp} replicate the
results for the 48-category-based unsmoothed and smoothed entropy measures
presented in Table~\ref{tab:reg_has_inflows_main} for reference. In columns (2)
and (4) we additionally control for the three entropy components. Including
these components has some effect: for unsmoothed entropy the magnitude of the
coefficient is less than half its size and the confidence interval is about
twice as wide, while for smoothed entropy the magnitude of the coefficient is a
little higher while the width of the confidence interval also roughly doubles.
However, both coefficients remain statistically significant and their
confidence intervals cover values that are also economically significant.
Hence, the results make clear that the results in
Table~\ref{tab:reg_has_inflows_main} cannot be attributed simply to the effect
of one or more of entropy's simple components.

Knowing that entropy is not simply the sum of its component parts still leaves
us with the question what it \textit{is} that entropy captures about user
spending distributions that is predictive of savings behaviour. We have not,
thus far, been able to understand this and leave the question for future
research.



