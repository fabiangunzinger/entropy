% !TEX root = ../entropy.tex

\section{Methods}%
\label{sec:methods}


\subsection{Dataset description}
\label{par:dataset_description}

We use data from Money Dashboard (MDB), a financial management app that allows
its users to link accounts from different banks to obtain an integrated view of
their
finances.\footnote{\href{https://www.moneydashboard.com}{https://www.moneydashboard.com}.}
The dataset contains more than 500 million transactions made between 2012 and
June 2020 by about 250,000 users, and provides information such as date,
amount, and description about the transaction as well as account and user-level
information.

The main advantages of the data for the study of consumer financial behaviour
are its high frequency, that it is automatically collected and updated and thus
less prone to errors and unaffected by biases that bedevil survey measures, and
that it offers a view of consumers' entire financial life across all their
accounts, rather than just a view of their accounts held at a single bank,
provided they added all their accounts to MDB. The main limitation is the
non-representativeness of the sample relative to the population as a whole.
Financial management apps are known to be used disproportionally by men,
younger people, and people of higher socioeconomic status
\citep{carlin2019generational}. Also, as pointed out in
\citet{gelman2014harnessing}, a willingness to share financial information with
a third party might not only select on demographic characteristics, but also
for an increased need for financial management or a higher degree of financial
sophistication. Because our analysis does not rely on representativeness, we do
not address this.\footnote{For an example of how re-weighing can be used to
mitigate the non-representative issue, see \citet{bourquin2020effects}.}


\paragraph{Data issues}%
\label{par:data_issues}

\citet{bourquin2020effects} argue that because some of the accounts in the data
will be joint accounts, units of observations should be tought of as
"households" rather than "users". We do not agree that this is the most prudent
approach. The validity of thinking of units as households depends on the
proportion of users in the data who add joint accounts and on the proportion of
transactions -- out of a user's total number of transactions -- additionally
observed as a result. Given that the sample is skewed towards younger
individuals we think it is unlikely that a majority of them has added joint
accounts. Furthermore, it seems reasonable to assume that in most cases, joint
accounts are mainly used for common household expenditures similar that are
similar to those of a single user (albeit in higher amounts), and are thus
unlikely to alter the observed spending profile much. Thus, we think of units
of observations as individuals, not households. 

Some accounts might be business accounts. Using versions of the algorightms
used by \citet{bourquin2020effects} to identify such accounts showed, however,
that such accounts only make up a tiny percentage of overall accounts and would
not influence our results. We thus do not exclude them.


\subsection{Preprocessing and sample selection}%
\label{par:preprocessing_and_sample_selection}

We restrict our sample to users for whom we can observe a regular income, can
be reasonably sure that they have added all their bank account to MDB, and for
whom we observe at least six months of data. Table~\ref{tab:selection}
summarises the sample selection steps we applied to a 1 percent sample of the
raw data, associated data losses, and the size of our final sample.

\begin{table}[H]
\centering
\caption{Sample selection}\label{tab:selection}
\input{\tabdir/sample_selection.tex}
\end{table}


\subsection{Dependent variables}
\label{sub:dependent_variables}

Identifying savings transactions: We classify as payments into savings accounts
all savings account credits of \pounds5 or more that are not identified as
interest payments or automated "save the change" transfers (similarly for
debits).\footnote{While standing order transactions are unlikely to be related
to entropy in the short-run, we do not exclude such transactions since, best we
can tell, the only account for a small fraction of total transactions.} 

Dummy for savings txn in current month. Motivation: \citet{mps2018building} finds that
saving habit is often more important than amount saved.


\subsection{Spending profiles}%
\label{sub:spending_profiles}

We define a user's spending profile as the distribution of the number of
spending transactionas across different spend categories.\footnote{There are a
    number of alternative ways to characterise spend profiles. We could
    calculate profiles based on the distribution of transaction values rather
    than counts. We could also calculate profiles based on inter-temporal
    rather than intra-temporal distributions, focusing on consistency of
    purchasing behaviour over time rather than on predictability at any given
    time \citep{krumme2013predictability}. Further, we could focus on
    time-based rather than category-based measures, focusing, for instance, on
    whether purchases of the same type tend to occur on the same day of the
    week \citep{guidotti2015behavioral}. Finally, one could also create
composite measures based on principal component analysis, an approach used in
\citet{eagle2010network}. We leave these extensions for future research.} To
summarise these distributions, we calculate spending entropy, based on the
formula proposed by \citet{shannon1948mathematical}, which defines entropy
as:\footnote{Shannon entropy is customarily denoted as $H$ following Shannon's
    own naming after Ludwig Boltzman's 1872 H-theorem in statistical mechanics,
to which it is analagous.}

\begin{equation}
\label{equ:entropy}
    H = -\sum{p_i}log(p_i),
\end{equation}

\noindent where $p_i$ is the probability that an individual makes a purchase in spending
category $i$, and $log$ is the base 2 logarithm.\footnote{The choice of the
    base for the logarithm varies by application and determines the units of
    $I(E)$. Base 2 means that information is expressed in bits. The natural
logarithm, another popular choice, expresses information in \textit{nats}.}

Entropy is a cornerstone of information theory, where it measures the amount of
information contained in an event. In the behavioural sciences, behavioural
entropy has recently been shown to predict the frequency of grocery visits and
the per-capita spend per visit \citep{guidotti2015behavioral}, the amount of
calories consumed \citep{skatova2019those}, and the propensity for financial
distress \citep{muggleton2020evidence}.

In the context of spending profiles, higher entropy means that transactions are
more equal across different spending categories, which makes it hard to predict
the next transaction, whereas low entropy profiles have the bulk of
transactions in a few dominant categories (such as groceries and
transportation) and have relatively few transactions in other
categories.\footnote{For further discussion on how to interpret
Equation~\ref{equ:entropy}, see Appendix~\ref{sec:entropy}.}

We calculate entropy based on three sets of spend categories. The first measure
is based on 9 spending categories used by
\citet{muggleton2020evidence}.\footnote{The precise mapping from MDB
    transaction tags into these 9 categories is available on
\href{https://github.com/fabiangunzinger/entropy/blob/7fa9c565bf8959ea92a9d4fe2245da0864e19c27/src/data/txn_classifications.py\#L249}{Github}.}
The second measure is based on our own, more fine-grained, categorisation into
48 different categories.\footnote{The precise mapping from MDB transaction tags
into these 48 categories is available on
\href{https://github.com/fabiangunzinger/entropy/blob/7fa9c565bf8959ea92a9d4fe2245da0864e19c27/src/data/txn_classifications.py\#L503}{Github}.}
The third measure is based on merchant names, as labelled by Money Dashboard.

We also handle categories with zero transaction counts in two different ways.
To calculate what we call ``unsmoothed'' entropy scores, we calculate the
$p_i$s in Equation~\ref{equ:entropy} as simple frequentist probabilities

\begin{equation}
    p_i^{us} = \frac{T_i}{\sum_{i=1}^{N}Ti},
\end{equation}

\noindent where $T_i$ is the number of transactions in spend category $i$ and
$N$ the number of categories. To avoid taking the log of zero for categories
with zero transactions, the sum in Equation~\ref{equ:entropy} is taken over
categories with positive transaction counts only.\footnote{This is
automatically handled by the entropy
\href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html}{implementation}
of Python's SciPy package, which is what we use to calculate entropy scores.}
To calculate ``smoothed'' entropy scores, we apply additive smoothing to
calculate propabilities as

\begin{equation}
    p_i^{s} = \frac{T_i + 1}{\sum_{i=1}^{N}Ti + N}.
\end{equation}

Because categories with a zero transaction count will have a numerator of 1,
the sum in Equation~\ref{equ:entropy} will be taken over all categories.

The imperfect transaction labelling in the MDB data creates a downward bias in
entropy scores for high-entropy individuals. This happens because unlabelled
transactions tend to be transactions that are rare (i.e. not grocery or Amazon
purchases), and it is high-entropy individuals that are more likely to engage
in rare transactions.


\subsection{Summary statistics}%
\label{par:summary_statistics}

Table~\ref{tab:sumstats} provides summary statistics.

\input{\tabdir/sumstats.tex}

Figure~\ref{fig:sample_desc}
\begin{figure}[H]
    \caption{Demographic characteristics of Money Dashboard users}
    \label{fig:sample_desc}
    \begin{center}
        \includegraphics[width=.9\textwidth]{\figdir/sample_desc.png}
    \end{center}
\end{figure}

Figure~\ref{fig:entropy_kdes}
\begin{figure}[H]
    \center \newcommand\width{\textwidth} \caption{Entropy distributions}
    \label{fig:entropy_kdes}
    \includegraphics[width=\width]{\figdir/entropy_kdes.png}
    \fignote{\width}{}
\end{figure}


\subsection{Model specification}%
\label{par:model_specification}

We estimate models of the form: 

\begin{equation}
    y_{i,t} = \alpha_i + \lambda_t + \beta H_{i,t} + x^\prime_{i,t} \delta +
    \epsilon_{i,t},
\end{equation}

\noindent where $y_{i,t}$ is an indicator variable equal to one if individual $i$ made
one or more transfers to any of their savings account in year-month period $t$ and zero
otherwise, $H_{it}$ is $i$'s spending entropy in year-month period $t$, $x_{i,t}$ a vector
of control variables, $\alpha_i$ an individual fixed effect, $\lambda_t$ a
year-month fixed effect, and $\epsilon_{i, t}$ the error term.

The vector of controls includes month spend, month income, an indicator for
whether a user had positive income in a given month, and income
variability, calculated as the standard deviation of month income over the
previous 12 months.

Note that while we might in principle be worried about reverse causality, since
making payments into savings accounts might lead to a non-zero count in an
additional spend category and thus change entropy, this is not a concern here.
As discussed in Section~\ref{sub:dependent_variables} and
Section~\ref{sub:spending_profiles}, we define savings as inflows into savings
accounts and define entropy based on the classification of spend transactions
on current accounts. If a user pays money from their current into one of their
savings account, this will usually be labelled in their current account as a
transfer and not enter the calculation of their entropy score. In
Appendix~\ref{sec:robustness}, we provide robustness checks using lagged
entropy scores and controlling for the number of non-zero categories, which
broadly leave the results unchanged.

