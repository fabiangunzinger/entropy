{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19817dbe-cdb0-4ec1-bbc2-9eb82e3ca122",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Notebook purpose\n",
    "\n",
    "- Understand nature of duplicate transactions, explore solutions, document decisions about what duplicates to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f59e33-f7e3-4139-a63f-8376b14a5a7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Types of duplicates\n",
    "\n",
    "Type 1 duplicates:  `['user_id', 'date', 'amount', 'account_id', 'desc']` are identical\n",
    "\n",
    "Type 2 duplicates: `['user_id', 'date', 'amount', 'account_id']` are identical and one `desc` is \"loose subset\" of the other (i.e. each word in one desc appears somewhere in the other, but can be out of order, though each pattern in other txn ).\n",
    "\n",
    "Approach taken:\n",
    "\n",
    "- Clean description string to remove extraneous characters that obfuscate type 1 duplicates. \n",
    "- Remove type 1 duplicates\n",
    "- Identify and remove type 2 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007cf749-c310-465e-8a3f-f4f1e898b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('/Users/fgu/dev/projects/entropy')\n",
    "import entropy.helpers.aws as aws\n",
    "import entropy.data.cleaners as cl\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('max_colwidth', None)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4723d277-c03a-4a35-ace2-a496272b2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aws.read_parquet('~/tmp/entropy_777.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae5657-88aa-4937-93ca-dcd37f73dd35",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b46115-1af4-4179-a47d-294c035c311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def counter(df):\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _get_potential_type2_dups(df):\n",
    "    \"\"\"Returns txns with identical user and account ids, dates, and amounts.\"\"\"\n",
    "    cols=['user_id', 'account_id', 'date', 'amount']\n",
    "    dups = df[df.duplicated(subset=cols, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(cols).ngroup()\n",
    "    return dups\n",
    "\n",
    "def _identify_type2_dups(df):\n",
    "    \"\"\"Returns index of Type2 duplicates.\"\"\"\n",
    "\n",
    "    def each_word_in_string(words, string):\n",
    "        \"\"\"Tests whether each word from words appears in string.\n",
    "        Allows each substring in string to be matched only once.\n",
    "        \"\"\"\n",
    "        unmatched = string\n",
    "        for w in words:\n",
    "            if w not in unmatched:\n",
    "                return False\n",
    "            unmatched = unmatched.replace(w, '', 1)\n",
    "        return True\n",
    "    \n",
    "    def identifier(g):\n",
    "        descriptions = [DescId(*i) for i in zip(g.desc, g.id)]\n",
    "        shortest, *others = sorted(descriptions, key=lambda x: len(x.desc))\n",
    "\n",
    "        for other in others:            \n",
    "            words, string = shortest.desc.split(), other.desc\n",
    "            answer = each_word_in_string(words, string)\n",
    "            if not answer:\n",
    "                words, string = other.desc.split(), shortest.desc\n",
    "                answer = each_word_in_string(words, string)\n",
    "            g.loc[g.id.eq(other.id), 'dup'] = answer\n",
    "\n",
    "        return g\n",
    "    \n",
    "    DescId = collections.namedtuple('DescId', ('desc', 'id'))\n",
    "    df['dup'] = False\n",
    "\n",
    "    df = df.groupby('group').apply(identifier)\n",
    "    return df[df.dup].index\n",
    "\n",
    "def drop_type2_dups(df):\n",
    "    \"\"\"Drops Type 2 duplicates.\n",
    "    \n",
    "    A Type 2 duplicate is one of two txns with identical user ids, txn ids,\n",
    "    account ids, dates, and amounts, as well as similar txn descriptions, \n",
    "    where \"similar\" means that each word in the description of one txn appears\n",
    "    in the description of the other.\n",
    "    \"\"\"\n",
    "    potential_dups = _get_potential_type2_dups(df)\n",
    "    dups_idx = _identify_type2_dups(potential_dups)\n",
    "    return df.drop(dups_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7657f2e5-1065-4e59-bf01-dc4833cdf2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123764, 31)\n",
      "(121188, 31)\n",
      "(121039, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                 mdbremoved\n",
       "1         9572 30dec 11 mcdonalds restaurant winwick road gb\n",
       "2              9572 31dec 11 tesco stores 3345 warrington gb\n",
       "3              9572 31dec 11 tesco stores 3345 warrington gb\n",
       "4                                                   aviva pa\n",
       "                                 ...                        \n",
       "123759                                        mdbremoved sto\n",
       "123760                             arthur lane on 29 jul clp\n",
       "123761                             wickes bury on 30 jul clp\n",
       "123762                        pets at home ltd on 30 jul clp\n",
       "123763                    9582 30jul 20 lidl gb bury bury gb\n",
       "Name: desc, Length: 121039, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = (df.pipe(counter)\n",
    "         .pipe(drop_type1_dups)\n",
    "         .pipe(counter)\n",
    "         .pipe(drop_type2_dups)\n",
    "         .pipe(counter))\n",
    "k1.desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce86a15-6ea7-461c-b2f6-381977908223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123764, 31)\n",
      "(121188, 31)\n",
      "(121093, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688261</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>400.00</td>\n",
       "      <td>mdbremoved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transfers</td>\n",
       "      <td>transfers</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>non merchant mbl</td>\n",
       "      <td>transfers</td>\n",
       "      <td>other account</td>\n",
       "      <td>other account</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>688264</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9572 30dec 11 mcdonalds restaurant winwick road gb</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>spend</td>\n",
       "      <td>services</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>dining and drinking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dining and drinking</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688263</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9572 31dec 11 tesco stores 3345 warrington gb</td>\n",
       "      <td>tesco</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>tesco supermarket</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>supermarket</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       date  user_id  amount  \\\n",
       "0  688261 2012-01-03      777  400.00   \n",
       "1  688264 2012-01-03      777   10.27   \n",
       "2  688263 2012-01-03      777    6.68   \n",
       "\n",
       "                                                 desc   merchant  tag_group  \\\n",
       "0                                          mdbremoved        NaN  transfers   \n",
       "1  9572 30dec 11 mcdonalds restaurant winwick road gb  mcdonalds      spend   \n",
       "2       9572 31dec 11 tesco stores 3345 warrington gb      tesco      spend   \n",
       "\n",
       "         tag user_female user_postcode user_registration_date  \\\n",
       "0  transfers       False         wa1 4             2011-07-20   \n",
       "1   services       False         wa1 4             2011-07-20   \n",
       "2  household       False         wa1 4             2011-07-20   \n",
       "\n",
       "  user_salary_range  user_yob account_created  account_id  \\\n",
       "0        20k to 30k    1969.0      2011-07-20      262916   \n",
       "1        20k to 30k    1969.0      2011-07-20      262916   \n",
       "2        20k to 30k    1969.0      2011-07-20      262916   \n",
       "\n",
       "  account_last_refreshed account_provider account_type  \\\n",
       "0    2020-07-21 20:32:00     natwest bank      current   \n",
       "1    2020-07-21 20:32:00     natwest bank      current   \n",
       "2    2020-07-21 20:32:00     natwest bank      current   \n",
       "\n",
       "  data_warehouse_date_created data_warehouse_date_last_updated  debit  \\\n",
       "0                  2014-07-18                       2017-11-13   True   \n",
       "1                  2014-07-18                       2015-03-19   True   \n",
       "2                  2014-07-18                       2017-08-15   True   \n",
       "\n",
       "   latest_balance merchant_business_line                    tag_auto  \\\n",
       "0      364.220001       non merchant mbl                   transfers   \n",
       "1      364.220001              mcdonalds         dining and drinking   \n",
       "2      364.220001      tesco supermarket  food, groceries, household   \n",
       "\n",
       "      tag_manual               tag_up updated_flag      ym      balance  \\\n",
       "0  other account        other account            u  201201 -1451.075562   \n",
       "1            NaN  dining and drinking            u  201201 -1451.075562   \n",
       "2            NaN          supermarket            u  201201 -1451.075562   \n",
       "\n",
       "         income  savings  \n",
       "0  24319.220881    False  \n",
       "1  24319.220881    False  \n",
       "2  24319.220881    False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark\n",
    "k0 = (df.pipe(counter)\n",
    "         .pipe(drop_type1_dups)\n",
    "         .pipe(counter)\n",
    "         .pipe(drop_type2_dups)\n",
    "         .pipe(counter))\n",
    "k0.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a3c38-e4a3-4cb2-995e-c202ec5f6f24",
   "metadata": {},
   "source": [
    "Features:\n",
    "- In groups larger than two, if others are related and shortest isn't, then we're unable to identify others as dups. (e.g.: `df.iloc[[1267567, 1267576, 1267577]]`)\n",
    "- If shorter is mdbremoved only, then conservatively classify as non-dup\n",
    "- Number matched to wrong equivalent [559240, 559242] -> each element in other should only match once\n",
    "- Groups with daily od charges, shortest without date not identified as dup\n",
    "\n",
    "Limitations:\n",
    "- If group contains two groups of duplicates, they are not identified\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66986022-58b7-46dc-9a3b-055c2d2b0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 32)\n",
      "(198, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>desc_old</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>109371611</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>777</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>mdbremoved fp 03 12 15 30 1 3000n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;mdbremoved&gt; fp 03/12/15 30 , 1xxxxxxxxxxxx3000n - s/o</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>non merchant mbl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>201512</td>\n",
       "      <td>366.253174</td>\n",
       "      <td>27638.970703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>109371621</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>777</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>8892 02dec 15 co op group 8054 warrington gb</td>\n",
       "      <td>co-op</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>True</td>\n",
       "      <td>8892 02dec15 , co-op group xx8054, warrington gb - pos</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>co-op supermarket</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>groceries</td>\n",
       "      <td>u</td>\n",
       "      <td>201512</td>\n",
       "      <td>366.253174</td>\n",
       "      <td>27638.970703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>109371614</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>777</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>8892 02dec 15 itunes com bill itunes com lu</td>\n",
       "      <td>apple</td>\n",
       "      <td>spend</td>\n",
       "      <td>services</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>True</td>\n",
       "      <td>8892 02dec15 , itunes.com/bill , itunes.com lu - pos</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>apple</td>\n",
       "      <td>entertainment, tv, media</td>\n",
       "      <td>lifestyle - other</td>\n",
       "      <td>lifestyle - other</td>\n",
       "      <td>u</td>\n",
       "      <td>201512</td>\n",
       "      <td>366.253174</td>\n",
       "      <td>27638.970703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>109551675</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>777</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>8892 03dec 15 amazon uk marketplace 6620 lu</td>\n",
       "      <td>amazon</td>\n",
       "      <td>spend</td>\n",
       "      <td>services</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>True</td>\n",
       "      <td>8892 03dec15 , amazon uk , marketplace , xxx-xxx-6620 lu - pos</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>amazon</td>\n",
       "      <td>enjoyment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>201512</td>\n",
       "      <td>312.183228</td>\n",
       "      <td>27638.970703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>109551674</td>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>777</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>8892 03dec 15 applegreen warrington gb</td>\n",
       "      <td>applegreen</td>\n",
       "      <td>spend</td>\n",
       "      <td>motor</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>True</td>\n",
       "      <td>8892 03dec15 , applegreen , warrington gb - pos</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>applegreen</td>\n",
       "      <td>fuel</td>\n",
       "      <td>fuel</td>\n",
       "      <td>fuel</td>\n",
       "      <td>u</td>\n",
       "      <td>201512</td>\n",
       "      <td>312.183228</td>\n",
       "      <td>27638.970703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>118238242</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>777</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>8892 16jan 16 tesco pfs 4010 warrington gb</td>\n",
       "      <td>tesco</td>\n",
       "      <td>spend</td>\n",
       "      <td>motor</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>8892 16jan16 , tesco pfs 4010 , warrington gb - pos</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>tesco fuel</td>\n",
       "      <td>fuel</td>\n",
       "      <td>groceries</td>\n",
       "      <td>groceries</td>\n",
       "      <td>c</td>\n",
       "      <td>201601</td>\n",
       "      <td>-804.166687</td>\n",
       "      <td>24264.291016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>118238239</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>777</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>o2</td>\n",
       "      <td>o2</td>\n",
       "      <td>spend</td>\n",
       "      <td>communication</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>o2 - d/d</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>o2</td>\n",
       "      <td>mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mobile</td>\n",
       "      <td>c</td>\n",
       "      <td>201601</td>\n",
       "      <td>-804.166687</td>\n",
       "      <td>24264.291016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>118238238</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>777</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>o2</td>\n",
       "      <td>o2</td>\n",
       "      <td>spend</td>\n",
       "      <td>communication</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>o2 - d/d</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>o2</td>\n",
       "      <td>mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mobile</td>\n",
       "      <td>c</td>\n",
       "      <td>201601</td>\n",
       "      <td>-804.166687</td>\n",
       "      <td>24264.291016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>118238241</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>777</td>\n",
       "      <td>-25.990000</td>\n",
       "      <td>8892 15jan 16 amazon uk marketplace 6620 lu refund</td>\n",
       "      <td>amazon</td>\n",
       "      <td>spend</td>\n",
       "      <td>retail</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>8892 15jan16 , amazon uk , marketplace , xxx-xxx-6620 lu , refund - pos</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>amazon</td>\n",
       "      <td>refunded purchase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>refunded purchase</td>\n",
       "      <td>c</td>\n",
       "      <td>201601</td>\n",
       "      <td>-804.166687</td>\n",
       "      <td>24264.291016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>118238236</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>777</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>dgi sky protect</td>\n",
       "      <td>sky protect</td>\n",
       "      <td>spend</td>\n",
       "      <td>finance</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>dgi sky protect - d/d</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>sky protect</td>\n",
       "      <td>home appliance insurance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home appliance insurance</td>\n",
       "      <td>c</td>\n",
       "      <td>201601</td>\n",
       "      <td>-804.166687</td>\n",
       "      <td>24264.291016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id       date  user_id     amount  \\\n",
       "3304  109371611 2015-12-03      777  15.000000   \n",
       "3305  109371621 2015-12-03      777  16.500000   \n",
       "3306  109371614 2015-12-03      777   3.990000   \n",
       "3307  109551675 2015-12-04      777  14.970000   \n",
       "3308  109551674 2015-12-04      777  39.099998   \n",
       "...         ...        ...      ...        ...   \n",
       "3500  118238242 2016-01-18      777  25.000000   \n",
       "3501  118238239 2016-01-18      777  21.240000   \n",
       "3502  118238238 2016-01-18      777  25.000000   \n",
       "3503  118238241 2016-01-18      777 -25.990000   \n",
       "3504  118238236 2016-01-18      777   9.990000   \n",
       "\n",
       "                                                    desc     merchant  \\\n",
       "3304                   mdbremoved fp 03 12 15 30 1 3000n          NaN   \n",
       "3305        8892 02dec 15 co op group 8054 warrington gb        co-op   \n",
       "3306         8892 02dec 15 itunes com bill itunes com lu        apple   \n",
       "3307         8892 03dec 15 amazon uk marketplace 6620 lu       amazon   \n",
       "3308              8892 03dec 15 applegreen warrington gb   applegreen   \n",
       "...                                                  ...          ...   \n",
       "3500          8892 16jan 16 tesco pfs 4010 warrington gb        tesco   \n",
       "3501                                                  o2           o2   \n",
       "3502                                                  o2           o2   \n",
       "3503  8892 15jan 16 amazon uk marketplace 6620 lu refund       amazon   \n",
       "3504                                     dgi sky protect  sky protect   \n",
       "\n",
       "     tag_group            tag user_female user_postcode  \\\n",
       "3304      None           None       False         wa1 4   \n",
       "3305     spend      household       False         wa1 4   \n",
       "3306     spend       services       False         wa1 4   \n",
       "3307     spend       services       False         wa1 4   \n",
       "3308     spend          motor       False         wa1 4   \n",
       "...        ...            ...         ...           ...   \n",
       "3500     spend          motor       False         wa1 4   \n",
       "3501     spend  communication       False         wa1 4   \n",
       "3502     spend  communication       False         wa1 4   \n",
       "3503     spend         retail       False         wa1 4   \n",
       "3504     spend        finance       False         wa1 4   \n",
       "\n",
       "     user_registration_date user_salary_range  user_yob account_created  \\\n",
       "3304             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3305             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3306             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3307             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3308             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "...                     ...               ...       ...             ...   \n",
       "3500             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3501             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3502             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3503             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "3504             2011-07-20        20k to 30k    1969.0      2011-07-20   \n",
       "\n",
       "      account_id account_last_refreshed account_provider account_type  \\\n",
       "3304      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3305      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3306      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3307      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3308      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "...          ...                    ...              ...          ...   \n",
       "3500      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3501      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3502      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3503      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "3504      262916    2020-07-21 20:32:00     natwest bank      current   \n",
       "\n",
       "     data_warehouse_date_created data_warehouse_date_last_updated  debit  \\\n",
       "3304                  2015-12-08                       2017-10-23   True   \n",
       "3305                  2015-12-08                       2017-08-12   True   \n",
       "3306                  2015-12-08                       2017-08-12   True   \n",
       "3307                  2015-12-09                       2017-08-12   True   \n",
       "3308                  2015-12-09                       2017-10-02   True   \n",
       "...                          ...                              ...    ...   \n",
       "3500                  2016-01-23                       1900-01-01   True   \n",
       "3501                  2016-01-23                       1900-01-01   True   \n",
       "3502                  2016-01-23                       1900-01-01   True   \n",
       "3503                  2016-01-23                       1900-01-01  False   \n",
       "3504                  2016-01-23                       1900-01-01   True   \n",
       "\n",
       "                                                                     desc_old  \\\n",
       "3304                   <mdbremoved> fp 03/12/15 30 , 1xxxxxxxxxxxx3000n - s/o   \n",
       "3305                   8892 02dec15 , co-op group xx8054, warrington gb - pos   \n",
       "3306                     8892 02dec15 , itunes.com/bill , itunes.com lu - pos   \n",
       "3307           8892 03dec15 , amazon uk , marketplace , xxx-xxx-6620 lu - pos   \n",
       "3308                          8892 03dec15 , applegreen , warrington gb - pos   \n",
       "...                                                                       ...   \n",
       "3500                      8892 16jan16 , tesco pfs 4010 , warrington gb - pos   \n",
       "3501                                                                 o2 - d/d   \n",
       "3502                                                                 o2 - d/d   \n",
       "3503  8892 15jan16 , amazon uk , marketplace , xxx-xxx-6620 lu , refund - pos   \n",
       "3504                                                    dgi sky protect - d/d   \n",
       "\n",
       "      latest_balance merchant_business_line                    tag_auto  \\\n",
       "3304      364.220001       non merchant mbl                         NaN   \n",
       "3305      364.220001      co-op supermarket  food, groceries, household   \n",
       "3306      364.220001                  apple    entertainment, tv, media   \n",
       "3307      364.220001                 amazon                   enjoyment   \n",
       "3308      364.220001             applegreen                        fuel   \n",
       "...              ...                    ...                         ...   \n",
       "3500      364.220001             tesco fuel                        fuel   \n",
       "3501      364.220001                     o2                      mobile   \n",
       "3502      364.220001                     o2                      mobile   \n",
       "3503      364.220001                 amazon           refunded purchase   \n",
       "3504      364.220001            sky protect    home appliance insurance   \n",
       "\n",
       "             tag_manual                    tag_up updated_flag      ym  \\\n",
       "3304                NaN                       NaN            u  201512   \n",
       "3305                NaN                 groceries            u  201512   \n",
       "3306  lifestyle - other         lifestyle - other            u  201512   \n",
       "3307                NaN                       NaN            u  201512   \n",
       "3308               fuel                      fuel            u  201512   \n",
       "...                 ...                       ...          ...     ...   \n",
       "3500          groceries                 groceries            c  201601   \n",
       "3501                NaN                    mobile            c  201601   \n",
       "3502                NaN                    mobile            c  201601   \n",
       "3503                NaN         refunded purchase            c  201601   \n",
       "3504                NaN  home appliance insurance            c  201601   \n",
       "\n",
       "         balance        income  savings  \n",
       "3304  366.253174  27638.970703    False  \n",
       "3305  366.253174  27638.970703    False  \n",
       "3306  366.253174  27638.970703    False  \n",
       "3307  312.183228  27638.970703    False  \n",
       "3308  312.183228  27638.970703    False  \n",
       "...          ...           ...      ...  \n",
       "3500 -804.166687  24264.291016    False  \n",
       "3501 -804.166687  24264.291016    False  \n",
       "3502 -804.166687  24264.291016    False  \n",
       "3503 -804.166687  24264.291016    False  \n",
       "3504 -804.166687  24264.291016    False  \n",
       "\n",
       "[198 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get potential dups\n",
    "# for each pairing in each group, check whether each word in string\n",
    "    # if yes, second is duplicate\n",
    "    # if no, second isn't duplicate\n",
    "\n",
    "# decisions:\n",
    "# - use combinations and if not answer pattern as above or \n",
    "#   simply check each word in string for each permutation in group\n",
    "# approach below uses latter, which is clean, but relies on there not being any type 1 dups in the data. do \n",
    "# i want to rely on this? probably not. want to be able to filter out dype 2 dups even when there are type 1 dups.\n",
    "# for this, though, I need a version of the if not answer pattern and combinations. think of nice way to do this. \n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def drop_type1_dups(df):\n",
    "    \"\"\"Drops Type 1 duplicates.\n",
    "    \n",
    "    A Type 1 duplicate is one of two txns with identical user and\n",
    "    account ids, dates, amounts, and txn descriptions.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    cols = ['user_id', 'account_id', 'date', 'amount', 'desc']\n",
    "    return df.drop_duplicates(subset=cols)\n",
    "\n",
    "\n",
    "def _potential_type2_dups(df):\n",
    "    \"\"\"Returns desc and duplicate group id for potential Type 2 duplicates.\"\"\"\n",
    "    cols = ['date', 'user_id', 'account_id', 'amount']\n",
    "    return (df.loc[df.duplicated(subset=cols, keep=False)]\n",
    "            .assign(group=lambda df: df.groupby(cols).ngroup())\n",
    "            .loc[:,['desc', 'group']])\n",
    "\n",
    "\n",
    "def _each_word_in_string(words, string):\n",
    "    \"\"\"Tests whether each word from words appears in string.\n",
    "    Allows each substring in string to be matched only once.\n",
    "    \"\"\"\n",
    "    unmatched = string\n",
    "    for w in words:\n",
    "        if w not in unmatched:\n",
    "            return False\n",
    "        unmatched = unmatched.replace(w, '', 1)\n",
    "    return True\n",
    "\n",
    "\n",
    "def _type2_dups_indices(g):\n",
    "    \"\"\"Checks for each txn pair in a group whether one txn is a Type 2\n",
    "    duplicate of the other, and returns idx of all duplicates.\n",
    "    \"\"\"\n",
    "    dups = []\n",
    "    pairs = list(itertools.combinations(g.index, 2))\n",
    "    for first, second in pairs:\n",
    "        words = g.loc[first].desc.split()\n",
    "        string = g.loc[second].desc\n",
    "        if _each_word_in_string(words, string):\n",
    "            dups.append(second)\n",
    "            break\n",
    "        words = g.loc[second].desc.split()\n",
    "        string = g.loc[first].desc\n",
    "        if _each_word_in_string(words, string):\n",
    "            dups.append(first)\n",
    "    return dups\n",
    "\n",
    "\n",
    "def drop_type2_dups(df):\n",
    "    \"\"\"Drops Type 2 duplicates.\n",
    "    \n",
    "    A Type 2 duplicate is a txn whose user id, account id, date, and amount\n",
    "    are identical to another txn, and whose txn description is similar to that\n",
    "    other txn, where \"similar\" means that each word in the txn description \n",
    "    appears in the description of the other txn.\n",
    "    \"\"\"   \n",
    "    potential_dups = _potential_type2_dups(df)    \n",
    "    dups = potential_dups.groupby('group').apply(_type2_dups_indices).sum()\n",
    "    return df.drop(dups)\n",
    "\n",
    "\n",
    "k = df.pipe(drop_type1_dups)[3300:3500].pipe(counter).pipe(drop_type2_dups).pipe(counter)\n",
    "k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62342c2a-09ed-4882-83e0-4780e89d3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c39f91b5-8c24-4466-9adb-0b249b8533ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>amazon prime 2454 79 00 pound sterling luxembourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>8892 15dec 15 itunes com bill itunes com lu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>dgi sky protect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>interest on your standard balance interest 1 5230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>8892 16jan 16 tesco pfs 4010 warrington gb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>o2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   desc  group\n",
       "3347  amazon prime 2454 79 00 pound sterling luxembourg      0\n",
       "3376        8892 15dec 15 itunes com bill itunes com lu      1\n",
       "3377                                    dgi sky protect      1\n",
       "3406  interest on your standard balance interest 1 5230      2\n",
       "3500         8892 16jan 16 tesco pfs 4010 warrington gb      3\n",
       "3502                                                 o2      3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.drop([3346, 3407])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beab8879-e728-4384-9eff-74eb6d7713aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122315</th>\n",
       "      <td>747676411</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>578777</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8450 18jul 19 c asda superstore farnworth gb</td>\n",
       "      <td>asda</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>True</td>\n",
       "      <td>bl8 2</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>30k to 40k</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>1648915</td>\n",
       "      <td>2020-08-16 20:04:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>709.489990</td>\n",
       "      <td>asda supermarket</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>c</td>\n",
       "      <td>201907</td>\n",
       "      <td>-1052.890137</td>\n",
       "      <td>22296.589844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122316</th>\n",
       "      <td>747726214</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>578777</td>\n",
       "      <td>50.00</td>\n",
       "      <td>bluedot on 19 jul bcc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>bl8 2</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>30k to 40k</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1649664</td>\n",
       "      <td>2020-08-16 20:04:00</td>\n",
       "      <td>barclays</td>\n",
       "      <td>current</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>266.179993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>201907</td>\n",
       "      <td>-1547.049316</td>\n",
       "      <td>22296.589844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122317</th>\n",
       "      <td>747726215</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>578777</td>\n",
       "      <td>20.00</td>\n",
       "      <td>bluedot on 19 jul bcc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>bl8 2</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>30k to 40k</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1649664</td>\n",
       "      <td>2020-08-16 20:04:00</td>\n",
       "      <td>barclays</td>\n",
       "      <td>current</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>266.179993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>201907</td>\n",
       "      <td>-1547.049316</td>\n",
       "      <td>22296.589844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122318</th>\n",
       "      <td>747726216</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>578777</td>\n",
       "      <td>20.00</td>\n",
       "      <td>bluedot on 19 jul bcc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>bl8 2</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>30k to 40k</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1649664</td>\n",
       "      <td>2020-08-16 20:04:00</td>\n",
       "      <td>barclays</td>\n",
       "      <td>current</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>266.179993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>201907</td>\n",
       "      <td>-1547.049316</td>\n",
       "      <td>22296.589844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122319</th>\n",
       "      <td>747726213</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>578777</td>\n",
       "      <td>25.33</td>\n",
       "      <td>lidl gb bury on 19 jul clp</td>\n",
       "      <td>lidl</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>True</td>\n",
       "      <td>bl8 2</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>30k to 40k</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1649664</td>\n",
       "      <td>2020-08-16 20:04:00</td>\n",
       "      <td>barclays</td>\n",
       "      <td>current</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>266.179993</td>\n",
       "      <td>lidl</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>c</td>\n",
       "      <td>201907</td>\n",
       "      <td>-1547.049316</td>\n",
       "      <td>22296.589844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       date  user_id  amount  \\\n",
       "122315  747676411 2019-07-19   578777    5.00   \n",
       "122316  747726214 2019-07-20   578777   50.00   \n",
       "122317  747726215 2019-07-20   578777   20.00   \n",
       "122318  747726216 2019-07-20   578777   20.00   \n",
       "122319  747726213 2019-07-20   578777   25.33   \n",
       "\n",
       "                                                desc merchant tag_group  \\\n",
       "122315  8450 18jul 19 c asda superstore farnworth gb     asda     spend   \n",
       "122316                         bluedot on 19 jul bcc      NaN      None   \n",
       "122317                         bluedot on 19 jul bcc      NaN      None   \n",
       "122318                         bluedot on 19 jul bcc      NaN      None   \n",
       "122319                    lidl gb bury on 19 jul clp     lidl     spend   \n",
       "\n",
       "              tag user_female user_postcode user_registration_date  \\\n",
       "122315  household        True         bl8 2             2020-03-29   \n",
       "122316       None        True         bl8 2             2020-03-29   \n",
       "122317       None        True         bl8 2             2020-03-29   \n",
       "122318       None        True         bl8 2             2020-03-29   \n",
       "122319  household        True         bl8 2             2020-03-29   \n",
       "\n",
       "       user_salary_range  user_yob account_created  account_id  \\\n",
       "122315        30k to 40k    1988.0      2020-03-29     1648915   \n",
       "122316        30k to 40k    1988.0      2020-03-30     1649664   \n",
       "122317        30k to 40k    1988.0      2020-03-30     1649664   \n",
       "122318        30k to 40k    1988.0      2020-03-30     1649664   \n",
       "122319        30k to 40k    1988.0      2020-03-30     1649664   \n",
       "\n",
       "       account_last_refreshed account_provider account_type  \\\n",
       "122315    2020-08-16 20:04:00     natwest bank      current   \n",
       "122316    2020-08-16 20:04:00         barclays      current   \n",
       "122317    2020-08-16 20:04:00         barclays      current   \n",
       "122318    2020-08-16 20:04:00         barclays      current   \n",
       "122319    2020-08-16 20:04:00         barclays      current   \n",
       "\n",
       "       data_warehouse_date_created data_warehouse_date_last_updated  debit  \\\n",
       "122315                  2020-03-30                       1900-01-01   True   \n",
       "122316                  2020-03-31                       1900-01-01   True   \n",
       "122317                  2020-03-31                       1900-01-01   True   \n",
       "122318                  2020-03-31                       1900-01-01   True   \n",
       "122319                  2020-03-31                       1900-01-01   True   \n",
       "\n",
       "        latest_balance merchant_business_line                    tag_auto  \\\n",
       "122315      709.489990       asda supermarket  food, groceries, household   \n",
       "122316      266.179993                    NaN                         NaN   \n",
       "122317      266.179993                    NaN                         NaN   \n",
       "122318      266.179993                    NaN                         NaN   \n",
       "122319      266.179993                   lidl  food, groceries, household   \n",
       "\n",
       "       tag_manual                      tag_up updated_flag      ym  \\\n",
       "122315        NaN  food, groceries, household            c  201907   \n",
       "122316        NaN                         NaN            c  201907   \n",
       "122317        NaN                         NaN            c  201907   \n",
       "122318        NaN                         NaN            c  201907   \n",
       "122319        NaN  food, groceries, household            c  201907   \n",
       "\n",
       "            balance        income  savings  \n",
       "122315 -1052.890137  22296.589844    False  \n",
       "122316 -1547.049316  22296.589844    False  \n",
       "122317 -1547.049316  22296.589844    False  \n",
       "122318 -1547.049316  22296.589844    False  \n",
       "122319 -1547.049316  22296.589844    False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[122315:122319].pipe(drop_type1_dups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f497bc31-c9ff-426f-90d0-3586bf272112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   desc  group\n",
      "437         bmach 23dec      0\n",
      "438  co operative 22dec      0\n",
      "                 desc  group\n",
      "437       bmach 23dec      0\n",
      "458  sainsburys 06jan      1\n",
      "                 desc  group\n",
      "437       bmach 23dec      0\n",
      "459  sainsburys 05jan      1\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "pairs = list(itertools.permutations(k.index, 2))[:3]\n",
    "for p in pairs:\n",
    "    print(k.loc[p,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177b92c-bce4-4ac1-bff0-76aa52a2f19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b958dd0-067e-4097-93cd-50cdbdf7b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "\n",
    "import functools\n",
    "\n",
    "def _potential_dup2_dups(df):\n",
    "    cols=['user_id', 'account_id', 'date', 'amount']\n",
    "    dups = df[df.duplicated(subset=cols, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(cols).ngroup()\n",
    "    return dups\n",
    "\n",
    "def _identify_dup2(df):\n",
    "    \n",
    "    def helper(group):\n",
    "    \n",
    "        group['dup'] = False\n",
    "\n",
    "        DescAndId = collections.namedtuple('DescAndID', ['desc', 'id'])\n",
    "        shortest_first = functools.partial(sorted, key=lambda x: len(x.desc))\n",
    "\n",
    "        items = [DescAndId(*item) for item in zip(group.desc, group.id)]\n",
    "        shortest, *others = shortest_first(items)\n",
    "\n",
    "        others_are_equal = len(set(others)) == 1\n",
    "        others_ids = [o.id for o in others]\n",
    "\n",
    "        if not others_are_equal:\n",
    "            answer = False\n",
    "        else:\n",
    "            remainder = others[0].desc\n",
    "            for w in shortest.desc.split():            \n",
    "                if w in remainder:\n",
    "                    remainder = remainder.replace(w, '', 1)\n",
    "                else:\n",
    "                    answer = False\n",
    "                    break\n",
    "                answer = True\n",
    "\n",
    "            if not answer:\n",
    "                remainder = shortest.desc\n",
    "                for w in others[0].desc.split():\n",
    "                    if w in remainder:                    \n",
    "                        remainder = remainder.replace(w, '', 1)\n",
    "                    else:\n",
    "                        answer = False\n",
    "                        break\n",
    "                    answer = True\n",
    "\n",
    "        group.loc[group.id.isin(others_ids), 'dup'] = answer\n",
    "        return group\n",
    "    \n",
    "    return df.groupby('group').apply(helper)\n",
    "\n",
    "\n",
    "\n",
    "def drop_dup2_old(df):\n",
    "    df = df.copy()\n",
    "    dups = _potential_dup2_dups(df)\n",
    "    dups = _identify_dup2(dups)\n",
    "    dups = dups[dups.dup].index\n",
    "    return df.drop(dups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e85cff-7708-4e0f-8be2-9ea8e7da588a",
   "metadata": {},
   "source": [
    "## Case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5d08a-03cc-4402-9f5e-357bc168cd6d",
   "metadata": {},
   "source": [
    "Below three case studies of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c789dfc-1995-478a-9084-a2c3e1bacddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 35177, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c1263-fed1-4c65-a662-89fdd71a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 362977, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de16e0d-e287-4363-899f-e4aea5211fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 467877, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f9ba0-f595-4913-b4dc-6a944f024e67",
   "metadata": {},
   "source": [
    "## Type 1 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "970e759c-85a3-406f-a3b4-a831312b437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distr(x):\n",
    "    pcts = [.01, .05, .1, .25, .50, .75, .90, .95, .99]\n",
    "    return x.describe(percentiles=pcts).round(2)\n",
    "\n",
    "def duplicates_sample(df, col_subset, n=100, seed=2312):\n",
    "    \"\"\"Draws sample of size n of duplicate txns as defined by col_subset.\"\"\"\n",
    "    dups = df[df.duplicated(subset=col_subset, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(col_subset).ngroup()\n",
    "    unique_groups = np.unique(dups.group)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    sample = rng.choice(unique_groups, size=n)\n",
    "    return dups[dups.group.isin(sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e4739-f864-4fcc-942e-211763e3eb8c",
   "metadata": {},
   "source": [
    "### Definition\n",
    "- `['user_id', 'date', 'amount', 'account_id', 'desc']` are identical.\n",
    " \n",
    "- This includes transactions where desc for both is `<mdbremoved>`, where we assume that they mask the same transaction desctiption.\n",
    "\n",
    "- Reasons for false positives (FP): user makes two identical transactions on the same day (or on subsequent days for txns that appear with a delay). Plausible cases are coffee and betting shop txns. However, inspection suggests that the vast majority of cases are genuine duplicates, as they are txns that are unlikely to result from multiple purchases on the same day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19018e7a-1db8-407b-bf69-49aaf8d96fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = ['user_id', 'date', 'amount', 'account_id', 'desc']\n",
    "dup_var = 'dup1'\n",
    "\n",
    "df[dup_var] = df.duplicated(subset=col_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705d1a1-dcc2-4965-878a-6884c072e657",
   "metadata": {},
   "source": [
    "### Prevalence and value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362605c-c7e2-4d16-857d-394ddafd7c46",
   "metadata": {},
   "source": [
    "How prevalent are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e536aa11-0bbf-4cc4-82ce-e869a384e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 1.9% of transactions across 97% of users are potential dups.\n"
     ]
    }
   ],
   "source": [
    "n_df = len(df)\n",
    "n_dups = len(df[df[dup_var]])\n",
    "n_users_dups = df[df[dup_var]].user_id.nunique()\n",
    "n_users_df = df.user_id.nunique()\n",
    "txt = 'About {:.1%} of transactions across {:.0%} of users are potential dups.'\n",
    "print(txt.format(n_dups / n_df, n_users_dups / n_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2720313-bd38-4ec8-b6ca-a33c4d6f1c6f",
   "metadata": {},
   "source": [
    "Gross value of duplicated txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f62c6a44-7a4f-48be-8555-d9051265b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       418.00\n",
       "mean       5042.84\n",
       "std       17571.44\n",
       "min           0.17\n",
       "1%            4.56\n",
       "5%           20.70\n",
       "10%          61.59\n",
       "25%         239.15\n",
       "50%         861.25\n",
       "75%        2763.97\n",
       "90%        9491.04\n",
       "95%       17296.48\n",
       "99%       66390.75\n",
       "max      190906.02\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_value = df[df[dup_var]].set_index('user_id').amount.abs().groupby('user_id').sum()\n",
    "distr(gross_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31eb24-ba24-4b9d-a649-2435c963eb9f",
   "metadata": {},
   "source": [
    "Most frequent txns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2750a738-1ad0-434c-995c-c754aece390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mdbremoved                                3059\n",
       "mdbremoved ft                              357\n",
       "tfl travel ch tfl gov uk cp                298\n",
       "tfl gov uk cp tfl travel ch                290\n",
       "paypal payment                             271\n",
       "b 365 moto                                 263\n",
       "tfl travel charge tfl gov uk cp            202\n",
       "betfair purchase                           196\n",
       "faster payments receipt ref mdbremoved     186\n",
       "www skybet com cd 9317                     165\n",
       "Name: desc, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].desc.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54a20b-3b69-4c10-8889-0b6bf5345a7b",
   "metadata": {},
   "source": [
    "Most frequent auto tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "640d2122-86d1-4c79-b267-58115fc7dae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                           7237\n",
       "transfers                     3066\n",
       "gambling                      2205\n",
       "enjoyment                     1609\n",
       "public transport              1557\n",
       "lunch or snacks               1157\n",
       "food, groceries, household     906\n",
       "bank charges                   873\n",
       "dining or going out            688\n",
       "entertainment, tv, media       568\n",
       "Name: tag_auto, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].tag_auto.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c358b-a46d-490e-8b38-bfc33e5a1398",
   "metadata": {},
   "source": [
    "Proportion of txns per auto tag that are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d7e18da-b4f6-45f6-bfce-0e0cbcb7795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investment - other               0.214953\n",
       "gambling                         0.160761\n",
       "mobile app                       0.152677\n",
       "isa                              0.088095\n",
       "tradesmen fees                   0.076923\n",
       "vehicle                          0.066667\n",
       "supermarket                      0.064968\n",
       "flights                          0.050346\n",
       "repayments                       0.047753\n",
       "child - everyday or childcare    0.047026\n",
       "Name: tag_auto, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns_per_tag_overall = df.tag_auto.value_counts(dropna=False)\n",
    "txns_per_tag_duplicated = df[df[dup_var]].tag_auto.value_counts(dropna=False) \n",
    "p_dup_per_tag = (txns_per_tag_duplicated / txns_per_tag_overall)\n",
    "p_dup_per_tag.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706bae3-e855-4884-9a64-ea0d74dec799",
   "metadata": {},
   "source": [
    "### Inspect dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ad40f06-39f0-4951-ad26-308cf318f325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642141     transfer from mdbremoved\n",
       "642142     transfer from mdbremoved\n",
       "1076408                  gocardless\n",
       "1076409                  gocardless\n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_sample(df, col_subset, n=2, seed=None).desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d9a00-1b50-496c-94b9-6a467945d83d",
   "metadata": {},
   "source": [
    "## Type 2 dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96068ec6-f1ee-410f-8c0c-9b813b125e01",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "- `['user_id', 'date', 'amount', 'account_id']` are identical, one `desc` is subset of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a63ba0-0993-49ae-968a-a86ba38d9df6",
   "metadata": {},
   "source": [
    "Remove type 1 dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a158035a-e989-4cf8-9718-39d127821211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=col_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a082f669-668f-4dc2-9027-7b931d02f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = ['user_id', 'date', 'amount', 'account_id']\n",
    "dup_var = 'dup2'\n",
    "\n",
    "df[dup_var] = df.duplicated(subset=col_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a359a0-cb12-4cd4-bff1-eacd1fff72a8",
   "metadata": {},
   "source": [
    "### Prevalence and value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba22152-d307-48fd-a036-1642ab2285bd",
   "metadata": {},
   "source": [
    "How prevalent are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "20b7d643-32bc-478e-a804-efdd59473560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 1.7% of transactions across 99% of users are potential dups.\n"
     ]
    }
   ],
   "source": [
    "n_df = len(df)\n",
    "n_dups = len(df[df[dup_var]])\n",
    "n_users_dups = df[df[dup_var]].user_id.nunique()\n",
    "n_users_df = df.user_id.nunique()\n",
    "txt = 'About {:.1%} of transactions across {:.0%} of users are potential dups.'\n",
    "print(txt.format(n_dups / n_df, n_users_dups / n_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5a50-197c-4c8a-a372-b41991168e55",
   "metadata": {},
   "source": [
    "Gross value of duplicated txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1115bb34-05f8-4c4d-8843-49d3805b7f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       424.00\n",
       "mean       2497.45\n",
       "std        8311.57\n",
       "min           3.00\n",
       "1%           11.08\n",
       "5%           48.28\n",
       "10%         104.04\n",
       "25%         298.47\n",
       "50%         880.35\n",
       "75%        2097.92\n",
       "90%        4584.54\n",
       "95%        6842.71\n",
       "99%       25811.31\n",
       "max      106598.39\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_value = df[df[dup_var]].set_index('user_id').amount.abs().groupby('user_id').sum()\n",
    "distr(gross_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf238fc0-691c-4f7a-b614-f7ca2fb66434",
   "metadata": {},
   "source": [
    "Most frequent txns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6390e1fc-d595-447c-9d4e-4fd4e912e13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdbremoved>    3523\n",
       "daily od fee    1894\n",
       "int'l xxxxxx     941\n",
       "card payment     463\n",
       "tfl travel c     336\n",
       "direct debit     319\n",
       "call ref.no.     308\n",
       "tfl.gov.uk/c     288\n",
       "contactless      281\n",
       "tesco stores     275\n",
       "Name: desc, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].desc.str[:12].value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de08a58-1f1b-4555-9907-815d3656d69c",
   "metadata": {},
   "source": [
    "Most frequent auto tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entropy",
   "language": "python",
   "name": "entropy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
