{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19817dbe-cdb0-4ec1-bbc2-9eb82e3ca122",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Notebook purpose\n",
    "\n",
    "- Understand nature of duplicate transactions, explore solutions, document decisions about what duplicates to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007cf749-c310-465e-8a3f-f4f1e898b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('/Users/fgu/dev/projects/entropy')\n",
    "import entropy.helpers.aws as aws\n",
    "import entropy.data.cleaners as cl\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('max_colwidth', None)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f59e33-f7e3-4139-a63f-8376b14a5a7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Solution\n",
    "\n",
    "Types of duplicates\n",
    "\n",
    "Type 1 duplicates:  `['user_id', 'date', 'amount', 'account_id', 'desc']` are identical\n",
    "\n",
    "Type 2 duplicates: `['user_id', 'date', 'amount', 'account_id']` are identical and one `desc` is \"loose subset\" of the other (i.e. each word in one desc appears somewhere in the other, but can be out of order, though each pattern in other txn ).\n",
    "\n",
    "Approach taken:\n",
    "\n",
    "- Clean description string to remove extraneous characters that obfuscate type 1 duplicates. \n",
    "- Remove type 1 duplicates\n",
    "- Identify and remove type 2 duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd29c3-e1d4-4f81-8d48-62e6d0fd3ff7",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4723d277-c03a-4a35-ace2-a496272b2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aws.read_parquet('~/tmp/entropy_777.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b958dd0-067e-4097-93cd-50cdbdf7b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def _potential_dup2_dups(df):\n",
    "    cols=['user_id', 'account_id', 'date', 'amount']\n",
    "    dups = df[df.duplicated(subset=cols, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(cols).ngroup()\n",
    "    return dups\n",
    "\n",
    "def _identify_dup2(df):\n",
    "    \n",
    "    def helper(group):\n",
    "    \n",
    "        group['dup'] = False\n",
    "\n",
    "        DescAndId = collections.namedtuple('DescAndID', ['desc', 'id'])\n",
    "        shortest_first = functools.partial(sorted, key=lambda x: len(x.desc))\n",
    "\n",
    "        items = [DescAndId(*item) for item in zip(group.desc, group.id)]\n",
    "        shortest, *others = shortest_first(items)\n",
    "\n",
    "        others_are_equal = len(set(others)) == 1\n",
    "        others_ids = [o.id for o in others]\n",
    "\n",
    "        if not others_are_equal:\n",
    "            answer = False\n",
    "        else:\n",
    "            remainder = others[0].desc\n",
    "            for w in shortest.desc.split():            \n",
    "                if w in remainder:\n",
    "                    remainder = remainder.replace(w, '', 1)\n",
    "                else:\n",
    "                    answer = False\n",
    "                    break\n",
    "                answer = True\n",
    "\n",
    "            if not answer:\n",
    "                remainder = shortest.desc\n",
    "                for w in others[0].desc.split():\n",
    "                    if w in remainder:                    \n",
    "                        remainder = remainder.replace(w, '', 1)\n",
    "                    else:\n",
    "                        answer = False\n",
    "                        break\n",
    "                    answer = True\n",
    "\n",
    "        group.loc[group.id.isin(others_ids), 'dup'] = answer\n",
    "        return group\n",
    "    \n",
    "    return df.groupby('group').apply(helper)\n",
    "\n",
    "\n",
    "\n",
    "def drop_dup2_old(df):\n",
    "    df = df.copy()\n",
    "    dups = _potential_dup2_dups(df)\n",
    "    dups = _identify_dup2(dups)\n",
    "    dups = dups[dups.dup].index\n",
    "    return df.drop(dups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08adfd39-71e2-4f22-ad24-037cfc51168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def clean_desc(df):\n",
    "    \"\"\"Removes extraneous characters that hinder duplicates detection.\n",
    "    \n",
    "    Removes common suffixes such as -vis, -p/p, and - e gbp; all\n",
    "    punctuation; multiple x characters, which are used to mask card\n",
    "    or account numbers: and extra whitespace. Also splits digits\n",
    "    suffixes -- but not prefixes, as these are usually dates -- from\n",
    "    words (e.g. 'no14' becomes 'no 14', '14jan' remains unchanged).\n",
    "    \"\"\"\n",
    "    import string\n",
    "    df = df.copy()\n",
    "    kwargs = dict(repl=' ', regex=True)\n",
    "    df['desc'] = (df.desc.str.replace(r'-\\s(\\w\\s)?.{2,3}$', **kwargs)\n",
    "                  .str.replace(fr'[{string.punctuation}]+', **kwargs)\n",
    "                  .str.replace(r'[x]{2,}', **kwargs)\n",
    "                  .str.replace(r'(?<=[a-zA-Z])(?=\\d)', **kwargs)\n",
    "                  .str.replace(r'\\s{2,}', **kwargs)\n",
    "                  .str.strip())\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_type1_dups(df):\n",
    "    \"\"\"Drops Type 1 duplicates.\n",
    "    \n",
    "    A Type 1 duplicate is one of two txns with identical user and\n",
    "    account ids, dates, amounts, and txn descriptions.\n",
    "    \"\"\"\n",
    "    cols = ['user_id', 'account_id', 'date', 'amount', 'desc']\n",
    "    return df.drop_duplicates(subset=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d1366c7-01a8-4de7-abe3-9090c2ae5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_potential_type2_dups(df):\n",
    "    \"\"\"Returns txns with identical user and account ids, dates, and amounts.\"\"\"\n",
    "    cols=['user_id', 'account_id', 'date', 'amount']\n",
    "    dups = df[df.duplicated(subset=cols, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(cols).ngroup()\n",
    "    return dups\n",
    "\n",
    "def _identify_type2_dups(df):\n",
    "    \"\"\"Returns index of Type2 duplicates.\"\"\"\n",
    "    \n",
    "    def are_identical(items):\n",
    "        return len(set(items)) == 1\n",
    "\n",
    "    def each_word_in_string(wordlist, string):\n",
    "        \"\"\"Tests whether each word from wordlist appears in string.\n",
    "        Allows each substring in string to be matched only once.\n",
    "        \"\"\"\n",
    "        unmatched = string\n",
    "        for w in wordlist:\n",
    "            if w not in unmatched:\n",
    "                return False\n",
    "            unmatched = unmatched.replace(w, '', 1)\n",
    "        return True\n",
    "    \n",
    "    def identifier(g):\n",
    "        descriptions = [DescId(*i) for i in zip(g.desc, g.id)]\n",
    "        shortest, *others = sorted(descriptions, key=lambda x: len(x.desc))\n",
    "        \n",
    "        if not are_identical(others):\n",
    "            return g\n",
    "        \n",
    "        #Â for each o in others: check below, and mark o.id as dup if answer is true\n",
    "        # try to refactor function so I can use in filter, which saves masking step in final return statement.\n",
    "\n",
    "        wordlist, string = shortest.desc.split(), others[0].desc\n",
    "        answer = each_word_in_string(wordlist, string)\n",
    "        if not answer:\n",
    "            wordlist, string = others[0].desc.split(), shortest.desc\n",
    "            answer = each_word_in_string(wordlist, string)\n",
    "        \n",
    "        others_ids = [o.id for o in others]\n",
    "\n",
    "        g.loc[g.id.isin(others_ids), 'dup'] = answer\n",
    "        return g\n",
    "    \n",
    "    DescId = collections.namedtuple('DescId', ('desc', 'id'))\n",
    "    df['dup'] = False\n",
    "    \n",
    "    df = df.groupby('group').apply(identifier)\n",
    "    return df[df.dup].index\n",
    "\n",
    "def drop_type2_dups(df):\n",
    "    \"\"\"Drops Type 2 duplicates.\n",
    "    \n",
    "    A Type 2 duplicate is one of two txns with identical user ids, txn ids,\n",
    "    account ids, dates, and amounts, as well as similar txn descriptions, \n",
    "    where \"similar\" means that each word in the description of one txn appears\n",
    "    in the description of the other.\n",
    "    \"\"\"    \n",
    "    potential_dups = _get_potential_type2_dups(df)\n",
    "    dups_idx = _identify_type2_dups(potential_dups)\n",
    "    return df.drop(dups_idx)\n",
    "\n",
    "def counter(df):\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ac89b72-a6b1-49a6-b9cb-c04b6bb1c501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121093, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688261</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>400.00</td>\n",
       "      <td>mdbremoved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transfers</td>\n",
       "      <td>tsransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>non merchant mbl</td>\n",
       "      <td>transfers</td>\n",
       "      <td>other account</td>\n",
       "      <td>other account</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>688264</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9572 30dec 11 mcdonalds restaurant winwick road gb</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>spend</td>\n",
       "      <td>services</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>dining and drinking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dining and drinking</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688263</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9572 31dec 11 tesco stores 3345 warrington gb</td>\n",
       "      <td>tesco</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>tesco supermarket</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>supermarket</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       date  user_id  amount  \\\n",
       "0  688261 2012-01-03      777  400.00   \n",
       "1  688264 2012-01-03      777   10.27   \n",
       "2  688263 2012-01-03      777    6.68   \n",
       "\n",
       "                                                 desc   merchant  tag_group  \\\n",
       "0                                          mdbremoved        NaN  transfers   \n",
       "1  9572 30dec 11 mcdonalds restaurant winwick road gb  mcdonalds      spend   \n",
       "2       9572 31dec 11 tesco stores 3345 warrington gb      tesco      spend   \n",
       "\n",
       "         tag user_female user_postcode user_registration_date  \\\n",
       "0  tsransfer       False         wa1 4             2011-07-20   \n",
       "1   services       False         wa1 4             2011-07-20   \n",
       "2  household       False         wa1 4             2011-07-20   \n",
       "\n",
       "  user_salary_range  user_yob account_created  account_id  \\\n",
       "0        20k to 30k    1969.0      2011-07-20      262916   \n",
       "1        20k to 30k    1969.0      2011-07-20      262916   \n",
       "2        20k to 30k    1969.0      2011-07-20      262916   \n",
       "\n",
       "  account_last_refreshed account_provider account_type  \\\n",
       "0    2020-07-21 20:32:00     natwest bank      current   \n",
       "1    2020-07-21 20:32:00     natwest bank      current   \n",
       "2    2020-07-21 20:32:00     natwest bank      current   \n",
       "\n",
       "  data_warehouse_date_created data_warehouse_date_last_updated  debit  \\\n",
       "0                  2014-07-18                       2017-11-13   True   \n",
       "1                  2014-07-18                       2015-03-19   True   \n",
       "2                  2014-07-18                       2017-08-15   True   \n",
       "\n",
       "   latest_balance merchant_business_line                    tag_auto  \\\n",
       "0      364.220001       non merchant mbl                   transfers   \n",
       "1      364.220001              mcdonalds         dining and drinking   \n",
       "2      364.220001      tesco supermarket  food, groceries, household   \n",
       "\n",
       "      tag_manual               tag_up updated_flag      ym      balance  \\\n",
       "0  other account        other account            u  201201 -1451.075562   \n",
       "1            NaN  dining and drinking            u  201201 -1451.075562   \n",
       "2            NaN          supermarket            u  201201 -1451.075562   \n",
       "\n",
       "         income  savings  \n",
       "0  24319.220881    False  \n",
       "1  24319.220881    False  \n",
       "2  24319.220881    False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = clean.pipe(drop_type2_dups)\n",
    "all(k0.index == k1.index)\n",
    "print(k1.shape)\n",
    "k1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f85d2dc-c649-4555-b060-4eb05e98fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_desc(df).pipe(drop_type1_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce86a15-6ea7-461c-b2f6-381977908223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121093, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688261</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>400.00</td>\n",
       "      <td>mdbremoved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transfers</td>\n",
       "      <td>tsransfer</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>non merchant mbl</td>\n",
       "      <td>transfers</td>\n",
       "      <td>other account</td>\n",
       "      <td>other account</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>688264</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9572 30dec 11 mcdonalds restaurant winwick road gb</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>spend</td>\n",
       "      <td>services</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>dining and drinking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dining and drinking</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688263</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>777</td>\n",
       "      <td>6.68</td>\n",
       "      <td>9572 31dec 11 tesco stores 3345 warrington gb</td>\n",
       "      <td>tesco</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>False</td>\n",
       "      <td>wa1 4</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2011-07-20</td>\n",
       "      <td>262916</td>\n",
       "      <td>2020-07-21 20:32:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>True</td>\n",
       "      <td>364.220001</td>\n",
       "      <td>tesco supermarket</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>supermarket</td>\n",
       "      <td>u</td>\n",
       "      <td>201201</td>\n",
       "      <td>-1451.075562</td>\n",
       "      <td>24319.220881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       date  user_id  amount  \\\n",
       "0  688261 2012-01-03      777  400.00   \n",
       "1  688264 2012-01-03      777   10.27   \n",
       "2  688263 2012-01-03      777    6.68   \n",
       "\n",
       "                                                 desc   merchant  tag_group  \\\n",
       "0                                          mdbremoved        NaN  transfers   \n",
       "1  9572 30dec 11 mcdonalds restaurant winwick road gb  mcdonalds      spend   \n",
       "2       9572 31dec 11 tesco stores 3345 warrington gb      tesco      spend   \n",
       "\n",
       "         tag user_female user_postcode user_registration_date  \\\n",
       "0  tsransfer       False         wa1 4             2011-07-20   \n",
       "1   services       False         wa1 4             2011-07-20   \n",
       "2  household       False         wa1 4             2011-07-20   \n",
       "\n",
       "  user_salary_range  user_yob account_created  account_id  \\\n",
       "0        20k to 30k    1969.0      2011-07-20      262916   \n",
       "1        20k to 30k    1969.0      2011-07-20      262916   \n",
       "2        20k to 30k    1969.0      2011-07-20      262916   \n",
       "\n",
       "  account_last_refreshed account_provider account_type  \\\n",
       "0    2020-07-21 20:32:00     natwest bank      current   \n",
       "1    2020-07-21 20:32:00     natwest bank      current   \n",
       "2    2020-07-21 20:32:00     natwest bank      current   \n",
       "\n",
       "  data_warehouse_date_created data_warehouse_date_last_updated  debit  \\\n",
       "0                  2014-07-18                       2017-11-13   True   \n",
       "1                  2014-07-18                       2015-03-19   True   \n",
       "2                  2014-07-18                       2017-08-15   True   \n",
       "\n",
       "   latest_balance merchant_business_line                    tag_auto  \\\n",
       "0      364.220001       non merchant mbl                   transfers   \n",
       "1      364.220001              mcdonalds         dining and drinking   \n",
       "2      364.220001      tesco supermarket  food, groceries, household   \n",
       "\n",
       "      tag_manual               tag_up updated_flag      ym      balance  \\\n",
       "0  other account        other account            u  201201 -1451.075562   \n",
       "1            NaN  dining and drinking            u  201201 -1451.075562   \n",
       "2            NaN          supermarket            u  201201 -1451.075562   \n",
       "\n",
       "         income  savings  \n",
       "0  24319.220881    False  \n",
       "1  24319.220881    False  \n",
       "2  24319.220881    False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k0 = clean.pipe(drop_dup2_old)\n",
    "print(k0.shape)\n",
    "k0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d838248-5e19-4220-9f2a-ad6cd5eefd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'midgleys cd 5714 deb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'midgleys cd 5714 deb'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare pre_post clean desc\n",
    "\n",
    "k = df.iloc[785793].to_frame().T\n",
    "display(k.desc.values[0])\n",
    "clean_desc(k).desc.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a3c38-e4a3-4cb2-995e-c202ec5f6f24",
   "metadata": {},
   "source": [
    "Features:\n",
    "- In groups larger than two, if others are related and shortest isn't, then we're unable to identify others as dups. (e.g.: `df.iloc[[1267567, 1267576, 1267577]]`)\n",
    "- If shorter is mdbremoved only, then conservatively classify as non-dup\n",
    "- Number matched to wrong equivalent [559240, 559242] -> each element in other should only match once\n",
    "- Groups with daily od charges, shortest without date not identified as dup\n",
    "\n",
    "Limitations:\n",
    "- If group contains two groups of duplicates, they are not identified\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88219632-b2b6-4233-ad03-1e869c250ea2",
   "metadata": {},
   "source": [
    "## Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479e412-8e57-40e8-a13e-6e13a53fd0fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f87da7-7278-4a56-a217-a1893c52a4a4",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1354a5a-94d1-4485-b8d6-7208e5d6f29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cefd5b-d9d1-426c-914f-c2ff85249ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ad8d6-f152-4e89-8439-cdf87cefa5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63253f54-d349-4435-862f-a06f473685be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aws.read_parquet('s3://3di-project-entropy/entropy_X77.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "970e759c-85a3-406f-a3b4-a831312b437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distr(x):\n",
    "    pcts = [.01, .05, .1, .25, .50, .75, .90, .95, .99]\n",
    "    return x.describe(percentiles=pcts).round(2)\n",
    "\n",
    "def duplicates_sample(df, col_subset, n=100, seed=2312):\n",
    "    \"\"\"Draws sample of size n of duplicate txns as defined by col_subset.\"\"\"\n",
    "    dups = df[df.duplicated(subset=col_subset, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(col_subset).ngroup()\n",
    "    unique_groups = np.unique(dups.group)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    sample = rng.choice(unique_groups, size=n)\n",
    "    return dups[dups.group.isin(sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e85cff-7708-4e0f-8be2-9ea8e7da588a",
   "metadata": {},
   "source": [
    "## Case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5d08a-03cc-4402-9f5e-357bc168cd6d",
   "metadata": {},
   "source": [
    "Below three case studies of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c789dfc-1995-478a-9084-a2c3e1bacddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 35177, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c1263-fed1-4c65-a662-89fdd71a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 362977, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de16e0d-e287-4363-899f-e4aea5211fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 467877, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f9ba0-f595-4913-b4dc-6a944f024e67",
   "metadata": {},
   "source": [
    "## Type 1 duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e4739-f864-4fcc-942e-211763e3eb8c",
   "metadata": {},
   "source": [
    "### Definition\n",
    "- `['user_id', 'date', 'amount', 'account_id', 'desc']` are identical.\n",
    " \n",
    "- This includes transactions where desc for both is `<mdbremoved>`, where we assume that they mask the same transaction desctiption.\n",
    "\n",
    "- Reasons for false positives (FP): user makes two identical transactions on the same day (or on subsequent days for txns that appear with a delay). Plausible cases are coffee and betting shop txns. However, inspection suggests that the vast majority of cases are genuine duplicates, as they are txns that are unlikely to result from multiple purchases on the same day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19018e7a-1db8-407b-bf69-49aaf8d96fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = ['user_id', 'date', 'amount', 'account_id', 'desc']\n",
    "dup_var = 'dup1'\n",
    "\n",
    "df[dup_var] = df.duplicated(subset=col_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705d1a1-dcc2-4965-878a-6884c072e657",
   "metadata": {},
   "source": [
    "### Prevalence and value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362605c-c7e2-4d16-857d-394ddafd7c46",
   "metadata": {},
   "source": [
    "How prevalent are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e536aa11-0bbf-4cc4-82ce-e869a384e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 1.7% of transactions across 97% of users are potential dups.\n"
     ]
    }
   ],
   "source": [
    "n_df = len(df)\n",
    "n_dups = len(df[df[dup_var]])\n",
    "n_users_dups = df[df[dup_var]].user_id.nunique()\n",
    "n_users_df = df.user_id.nunique()\n",
    "txt = 'About {:.1%} of transactions across {:.0%} of users are potential dups.'\n",
    "print(txt.format(n_dups / n_df, n_users_dups / n_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2720313-bd38-4ec8-b6ca-a33c4d6f1c6f",
   "metadata": {},
   "source": [
    "Gross value of duplicated txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f62c6a44-7a4f-48be-8555-d9051265b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       415.00\n",
       "mean       4459.53\n",
       "std       14957.93\n",
       "min           1.00\n",
       "1%            4.54\n",
       "5%           20.46\n",
       "10%          61.97\n",
       "25%         237.31\n",
       "50%         830.10\n",
       "75%        2647.96\n",
       "90%        8980.22\n",
       "95%       16434.12\n",
       "99%       59013.14\n",
       "max      183754.34\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_value = df[df[dup_var]].set_index('user_id').amount.abs().groupby('user_id').sum()\n",
    "distr(gross_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31eb24-ba24-4b9d-a649-2435c963eb9f",
   "metadata": {},
   "source": [
    "Most frequent txns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2750a738-1ad0-434c-995c-c754aece390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdbremoved>                       1962\n",
       "<mdbremoved>                        516\n",
       "<mdbremoved> ft                     359\n",
       "b365 moto                           263\n",
       "paypal payment                      195\n",
       "tfl travel charge tfl.gov.uk/cp     167\n",
       "www.skybet.com cd 9317              165\n",
       "<mdbremoved> so                     157\n",
       "betfair.-purchase                   146\n",
       "<mdbremoved> - s/o                  143\n",
       "Name: desc, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].desc.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54a20b-3b69-4c10-8889-0b6bf5345a7b",
   "metadata": {},
   "source": [
    "Most frequent auto tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "640d2122-86d1-4c79-b267-58115fc7dae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                         6104\n",
       "transfers                   3260\n",
       "gambling                    2273\n",
       "enjoyment                   1617\n",
       "public transport            1132\n",
       "lunch or snacks             1019\n",
       "bank charges                 862\n",
       "entertainment, tv, media     556\n",
       "cash                         520\n",
       "dining or going out          507\n",
       "Name: tag_auto, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].tag_auto.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c358b-a46d-490e-8b38-bfc33e5a1398",
   "metadata": {},
   "source": [
    "Proportion of txns per auto tag that are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d7e18da-b4f6-45f6-bfce-0e0cbcb7795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investment - other              0.227723\n",
       "gambling                        0.162822\n",
       "mobile app                      0.147576\n",
       "isa                             0.090024\n",
       "tradesmen fees                  0.062500\n",
       "flights                         0.050548\n",
       "parking                         0.046441\n",
       "payment protection insurance    0.044776\n",
       "paypal account                  0.044444\n",
       "bills                           0.044291\n",
       "Name: tag_auto, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns_per_tag_overall = df.tag_auto.value_counts(dropna=False)\n",
    "txns_per_tag_duplicated = df[df[dup_var]].tag_auto.value_counts(dropna=False) \n",
    "p_dup_per_tag = (txns_per_tag_duplicated / txns_per_tag_overall)\n",
    "p_dup_per_tag.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706bae3-e855-4884-9a64-ea0d74dec799",
   "metadata": {},
   "source": [
    "### Inspect dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ad40f06-39f0-4951-ad26-308cf318f325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275216       <mdbremoved>\n",
       "275217       <mdbremoved>\n",
       "726133    <mdbremoved> so\n",
       "726134    <mdbremoved> so\n",
       "Name: desc, dtype: category\n",
       "Categories (2359486, object): [' <mdbremoved> ', ' <mdbremoved>  & co llp - d/d', ' <mdbremoved>  & co store ltd', ' <mdbremoved>  & company cd 6426', ..., 'Ã³b Ã­safirdi', 'Ã¶l & vin magasinet stockholm', 'Ã¹appleseed books and p guildford', 'Ãºri cipÃ¶ - kaptafa']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_sample(df, col_subset, n=2, seed=None).desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d9a00-1b50-496c-94b9-6a467945d83d",
   "metadata": {},
   "source": [
    "## Type 2 dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96068ec6-f1ee-410f-8c0c-9b813b125e01",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "- `['user_id', 'date', 'amount', 'account_id']` are identical, one `desc` is subset of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a63ba0-0993-49ae-968a-a86ba38d9df6",
   "metadata": {},
   "source": [
    "Remove type 1 dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a158035a-e989-4cf8-9718-39d127821211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=col_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a082f669-668f-4dc2-9027-7b931d02f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = ['user_id', 'date', 'amount', 'account_id']\n",
    "dup_var = 'dup2'\n",
    "\n",
    "df[dup_var] = df.duplicated(subset=col_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a359a0-cb12-4cd4-bff1-eacd1fff72a8",
   "metadata": {},
   "source": [
    "### Prevalence and value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba22152-d307-48fd-a036-1642ab2285bd",
   "metadata": {},
   "source": [
    "How prevalent are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20b7d643-32bc-478e-a804-efdd59473560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 1.9% of transactions across 99% of users are potential dups.\n"
     ]
    }
   ],
   "source": [
    "n_df = len(df)\n",
    "n_dups = len(df[df[dup_var]])\n",
    "n_users_dups = df[df[dup_var]].user_id.nunique()\n",
    "n_users_df = df.user_id.nunique()\n",
    "txt = 'About {:.1%} of transactions across {:.0%} of users are potential dups.'\n",
    "print(txt.format(n_dups / n_df, n_users_dups / n_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5a50-197c-4c8a-a372-b41991168e55",
   "metadata": {},
   "source": [
    "Gross value of duplicated txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1115bb34-05f8-4c4d-8843-49d3805b7f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       424.00\n",
       "mean       2497.45\n",
       "std        8311.57\n",
       "min           3.00\n",
       "1%           11.08\n",
       "5%           48.28\n",
       "10%         104.04\n",
       "25%         298.47\n",
       "50%         880.35\n",
       "75%        2097.92\n",
       "90%        4584.54\n",
       "95%        6842.71\n",
       "99%       25811.31\n",
       "max      106598.39\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_value = df[df[dup_var]].set_index('user_id').amount.abs().groupby('user_id').sum()\n",
    "distr(gross_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf238fc0-691c-4f7a-b614-f7ca2fb66434",
   "metadata": {},
   "source": [
    "Most frequent txns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6390e1fc-d595-447c-9d4e-4fd4e912e13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdbremoved>    3523\n",
       "daily od fee    1894\n",
       "int'l xxxxxx     941\n",
       "card payment     463\n",
       "tfl travel c     336\n",
       "direct debit     319\n",
       "call ref.no.     308\n",
       "tfl.gov.uk/c     288\n",
       "contactless      281\n",
       "tesco stores     275\n",
       "Name: desc, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].desc.str[:12].value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de08a58-1f1b-4555-9907-815d3656d69c",
   "metadata": {},
   "source": [
    "Most frequent auto tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entropy",
   "language": "python",
   "name": "entropy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
