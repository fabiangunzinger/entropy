{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13bef683-64f8-4c36-bec3-05ecb69b15c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('/Users/fgu/dev/projects/entropy')\n",
    "import entropy.helpers.aws as aws\n",
    "import entropy.data.cleaners as cl\n",
    "import entropy.data.helpers as dh\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('max_colwidth', None)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585fbeec-b261-40d2-bd56-cb42d828b773",
   "metadata": {},
   "source": [
    "Notebook purpose\n",
    "\n",
    "- Understand nature of duplicate transactions and explore solutions\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. `['user_id', 'date', 'amount', 'account_id', 'desc']` are identical -> drop in main analysis.\n",
    "\n",
    "2. `['user_id', 'date', 'amount', 'account_id']` are identical and `desc` is similar -> drop from main analysis. *\n",
    "\n",
    "3. `['user_id', 'date', 'amount', 'account_id']` are identical and `desc` not similar -> keep in main analysis.\n",
    "\n",
    "4. `['user_id', 'date', 'amount']`, `desc` may or may not differ, but `account_id` differs. This is relevant if there are (many) duplicated accounts, in which case a different account number is no guarantee for a different account. -> ignore for now, ask MDB to get list of duplicated accounts.\n",
    "\n",
    "\n",
    "\\* in this category we include cases where desc of one txn is `<mdbremoved>` while other isn't, so even though descriptions are not similar in this case, we assume that redaction masks available description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4723d277-c03a-4a35-ace2-a496272b2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('~/tmp/entropy_X77.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8009f0f-348e-4881-a172-bf62964bbfea",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "970e759c-85a3-406f-a3b4-a831312b437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distr(x):\n",
    "    pcts = [.01, .05, .1, .25, .50, .75, .90, .95, .99]\n",
    "    return x.describe(percentiles=pcts).round(2)\n",
    "\n",
    "def dup_txn_sample(df, col_subset, n=100, seed=2312):\n",
    "    \"\"\"Draws sample of size n of duplicate txns as defined by col_subset.\"\"\"\n",
    "    dups = df[df.duplicated(subset=col_subset, keep=False)].copy()\n",
    "    dups['group'] = dups.groupby(col_subset).ngroup()\n",
    "    unique_groups = np.unique(dups.group)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    sample = rng.choice(unique_groups, size=n)\n",
    "    return dups[dups.group.isin(sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e85cff-7708-4e0f-8be2-9ea8e7da588a",
   "metadata": {},
   "source": [
    "## Case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5d08a-03cc-4402-9f5e-357bc168cd6d",
   "metadata": {},
   "source": [
    "Below three case studies of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c789dfc-1995-478a-9084-a2c3e1bacddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 35177, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c1263-fed1-4c65-a662-89fdd71a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 362977, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de16e0d-e287-4363-899f-e4aea5211fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.user_date_data(df, 467877, '1 Jan 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f9ba0-f595-4913-b4dc-6a944f024e67",
   "metadata": {},
   "source": [
    "## Type 1 duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e4739-f864-4fcc-942e-211763e3eb8c",
   "metadata": {},
   "source": [
    "### Definition\n",
    "- `['user_id', 'date', 'amount', 'account_id', 'desc']` are identical.\n",
    " \n",
    "- This includes transactions where desc for both is `<mdbremoved>`, where we have to make a call whether or not to assume they are the same.\n",
    "\n",
    "- Reasons for false positives (FP): user makes two identical transactions on the same day (or on subsequent days for txns that appear with a delay). Plausible cases are coffee and betting shop txns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19018e7a-1db8-407b-bf69-49aaf8d96fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_subset = ['user_id', 'date', 'amount', 'account_id', 'desc']\n",
    "dup_var = 'dup1'\n",
    "\n",
    "df[dup_var] = df.duplicated(subset=dup_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705d1a1-dcc2-4965-878a-6884c072e657",
   "metadata": {},
   "source": [
    "### Prevalence and value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362605c-c7e2-4d16-857d-394ddafd7c46",
   "metadata": {},
   "source": [
    "How prevalent are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e536aa11-0bbf-4cc4-82ce-e869a384e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 1.7% of transactions across 97% of users are potential dups.\n"
     ]
    }
   ],
   "source": [
    "n_df = len(df)\n",
    "n_dups = len(df[df[dup_var]])\n",
    "n_users_dups = df[df[dup_var]].user_id.nunique()\n",
    "n_users_df = df.user_id.nunique()\n",
    "txt = 'About {:.1%} of transactions across {:.0%} of users are potential dups.'\n",
    "print(txt.format(n_dups / n_df, n_users_dups / n_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2720313-bd38-4ec8-b6ca-a33c4d6f1c6f",
   "metadata": {},
   "source": [
    "Gross value of duplicated txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f62c6a44-7a4f-48be-8555-d9051265b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       415.00\n",
       "mean       4459.53\n",
       "std       14957.93\n",
       "min           1.00\n",
       "1%            4.54\n",
       "5%           20.46\n",
       "10%          61.97\n",
       "25%         237.31\n",
       "50%         830.10\n",
       "75%        2647.96\n",
       "90%        8980.22\n",
       "95%       16434.12\n",
       "99%       59013.14\n",
       "max      183754.34\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_value = df[df[dup_var]].set_index('user_id').amount.abs().groupby('user_id').sum()\n",
    "distr(gross_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31eb24-ba24-4b9d-a649-2435c963eb9f",
   "metadata": {},
   "source": [
    "Most frequent txns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2750a738-1ad0-434c-995c-c754aece390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdbremoved>                       1962\n",
       "<mdbremoved>                        516\n",
       "<mdbremoved> ft                     359\n",
       "b365 moto                           263\n",
       "paypal payment                      195\n",
       "tfl travel charge tfl.gov.uk/cp     167\n",
       "www.skybet.com cd 9317              165\n",
       "<mdbremoved> so                     157\n",
       "betfair.-purchase                   146\n",
       "<mdbremoved> - s/o                  143\n",
       "Name: desc, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].desc.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54a20b-3b69-4c10-8889-0b6bf5345a7b",
   "metadata": {},
   "source": [
    "Most frequent auto tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "640d2122-86d1-4c79-b267-58115fc7dae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                         6326\n",
       "transfers                   3038\n",
       "gambling                    2273\n",
       "enjoyment                   1617\n",
       "public transport            1132\n",
       "lunch or snacks             1019\n",
       "bank charges                 862\n",
       "entertainment, tv, media     556\n",
       "cash                         520\n",
       "dining or going out          507\n",
       "Name: tag_auto, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].tag_auto.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c358b-a46d-490e-8b38-bfc33e5a1398",
   "metadata": {},
   "source": [
    "Proportion of txns per auto tag that are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d7e18da-b4f6-45f6-bfce-0e0cbcb7795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repayments                       0.303867\n",
       "legal                            0.175299\n",
       "saving (general)                 0.125000\n",
       "vet                              0.104603\n",
       "investment - other               0.102564\n",
       "gambling                         0.094977\n",
       "media bundle                     0.088889\n",
       "bank charges                     0.078101\n",
       "social club                      0.076923\n",
       "isa                              0.066845\n",
       "vehicle                          0.066667\n",
       "school fees                      0.066667\n",
       "store card repayment             0.057554\n",
       "payday loan funds                0.057143\n",
       "cash                             0.051044\n",
       "investments or shares            0.050505\n",
       "supermarket                      0.050198\n",
       "vehicle hire                     0.046154\n",
       "cycling                          0.041162\n",
       "bills                            0.040550\n",
       "child - everyday or childcare    0.038734\n",
       "hobbies or activities            0.037280\n",
       "sports equipment                 0.036217\n",
       "interest charges                 0.036202\n",
       "current account                  0.035160\n",
       "public transport                 0.031506\n",
       "student loan repayment           0.030864\n",
       "pension or investments           0.029828\n",
       "donation to organisation         0.029808\n",
       "toys                             0.028777\n",
       "vehicle running costs            0.027027\n",
       "rent                             0.026745\n",
       "software                         0.025995\n",
       "course and tuition fees          0.025974\n",
       "electricity                      0.025641\n",
       "mortgage or rent                 0.025572\n",
       "taxi                             0.024503\n",
       "mobile phone insurance           0.023529\n",
       "games and gaming                 0.023050\n",
       "accessories                      0.022989\n",
       "Name: tag_auto, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns_per_tag_overall = df.tag_auto.value_counts(dropna=False)\n",
    "txns_per_tag_duplicated = df[df[dup_var]].tag_auto.value_counts(dropna=False) \n",
    "p_dup_per_tag = (txns_per_tag_duplicated / txns_per_tag_overall)\n",
    "p_dup_per_tag.sort_values(ascending=False)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d6dfc-bdf2-47aa-baa9-efd79893fd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f706bae3-e855-4884-9a64-ea0d74dec799",
   "metadata": {},
   "source": [
    "### Inspect dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ad40f06-39f0-4951-ad26-308cf318f325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "      <th>dup1</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739537</th>\n",
       "      <td>494439523</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>434077</td>\n",
       "      <td>-270.0</td>\n",
       "      <td>&lt;mdbremoved&gt; via online - pymt - dpc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>e9 6</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>928688</td>\n",
       "      <td>2020-03-11 09:41:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>False</td>\n",
       "      <td>7038.149902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>201901</td>\n",
       "      <td>6662.920410</td>\n",
       "      <td>15507.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739538</th>\n",
       "      <td>494439524</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>434077</td>\n",
       "      <td>-270.0</td>\n",
       "      <td>&lt;mdbremoved&gt; via online - pymt - dpc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>e9 6</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>928688</td>\n",
       "      <td>2020-03-11 09:41:00</td>\n",
       "      <td>natwest bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>False</td>\n",
       "      <td>7038.149902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>201901</td>\n",
       "      <td>6662.920410</td>\n",
       "      <td>15507.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774834</th>\n",
       "      <td>510986520</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>440877</td>\n",
       "      <td>2.3</td>\n",
       "      <td>www.justpark.com, internet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spend</td>\n",
       "      <td>motor</td>\n",
       "      <td>False</td>\n",
       "      <td>w3 9</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>70k to 80k</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>959817</td>\n",
       "      <td>2020-08-16 00:56:00</td>\n",
       "      <td>barclaycard</td>\n",
       "      <td>credit card</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>-28.580000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking</td>\n",
       "      <td>c</td>\n",
       "      <td>201902</td>\n",
       "      <td>575.950134</td>\n",
       "      <td>78606.601562</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774835</th>\n",
       "      <td>510986521</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>440877</td>\n",
       "      <td>2.3</td>\n",
       "      <td>www.justpark.com, internet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spend</td>\n",
       "      <td>motor</td>\n",
       "      <td>False</td>\n",
       "      <td>w3 9</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>70k to 80k</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>959817</td>\n",
       "      <td>2020-08-16 00:56:00</td>\n",
       "      <td>barclaycard</td>\n",
       "      <td>credit card</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>-28.580000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parking</td>\n",
       "      <td>c</td>\n",
       "      <td>201902</td>\n",
       "      <td>575.950134</td>\n",
       "      <td>78606.601562</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       date  user_id  amount  \\\n",
       "739537  494439523 2019-01-02   434077  -270.0   \n",
       "739538  494439524 2019-01-02   434077  -270.0   \n",
       "774834  510986520 2019-02-09   440877     2.3   \n",
       "774835  510986521 2019-02-09   440877     2.3   \n",
       "\n",
       "                                        desc merchant tag_group    tag  \\\n",
       "739537  <mdbremoved> via online - pymt - dpc      NaN      None   None   \n",
       "739538  <mdbremoved> via online - pymt - dpc      NaN      None   None   \n",
       "774834            www.justpark.com, internet      NaN     spend  motor   \n",
       "774835            www.justpark.com, internet      NaN     spend  motor   \n",
       "\n",
       "       user_female user_postcode user_registration_date user_salary_range  \\\n",
       "739537       False          e9 6             2018-04-06               NaN   \n",
       "739538       False          e9 6             2018-04-06               NaN   \n",
       "774834       False          w3 9             2018-05-23        70k to 80k   \n",
       "774835       False          w3 9             2018-05-23        70k to 80k   \n",
       "\n",
       "        user_yob account_created  account_id account_last_refreshed  \\\n",
       "739537    1967.0      2018-04-06      928688    2020-03-11 09:41:00   \n",
       "739538    1967.0      2018-04-06      928688    2020-03-11 09:41:00   \n",
       "774834    1965.0      2018-05-23      959817    2020-08-16 00:56:00   \n",
       "774835    1965.0      2018-05-23      959817    2020-08-16 00:56:00   \n",
       "\n",
       "       account_provider account_type data_warehouse_date_created  \\\n",
       "739537     natwest bank      current                  2019-01-11   \n",
       "739538     natwest bank      current                  2019-01-11   \n",
       "774834      barclaycard  credit card                  2019-02-13   \n",
       "774835      barclaycard  credit card                  2019-02-13   \n",
       "\n",
       "       data_warehouse_date_last_updated  debit  latest_balance  \\\n",
       "739537                       2019-02-04  False     7038.149902   \n",
       "739538                       2019-02-04  False     7038.149902   \n",
       "774834                       1900-01-01   True      -28.580000   \n",
       "774835                       1900-01-01   True      -28.580000   \n",
       "\n",
       "       merchant_business_line tag_auto tag_manual   tag_up updated_flag  \\\n",
       "739537                    NaN      NaN        NaN      NaN            u   \n",
       "739538                    NaN      NaN        NaN      NaN            u   \n",
       "774834                    NaN  parking        NaN  parking            c   \n",
       "774835                    NaN  parking        NaN  parking            c   \n",
       "\n",
       "            ym      balance        income  savings   dup1  group  \n",
       "739537  201901  6662.920410  15507.500000    False  False  10141  \n",
       "739538  201901  6662.920410  15507.500000    False   True  10141  \n",
       "774834  201902   575.950134  78606.601562    False  False  10719  \n",
       "774835  201902   575.950134  78606.601562    False   True  10719  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_txn_sample(df, dup_subset, n=2, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea96e3-11c7-4f5c-aded-7e71bc929eea",
   "metadata": {},
   "source": [
    "### Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e151ad-27fb-4397-a10a-00819e0d23dc",
   "metadata": {},
   "source": [
    "- We delete dups for main analysis and do robustness check withouth deleting them\n",
    "- We tread cases where both descriptions are `<mdbremoved>` no different from others, even though it's somewhat more likely that they are genuinely different transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c4983a9-216f-4472-bd5e-3bbc0b6ca485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=dup_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d9a00-1b50-496c-94b9-6a467945d83d",
   "metadata": {},
   "source": [
    "## Type 2 dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96068ec6-f1ee-410f-8c0c-9b813b125e01",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "- `['user_id', 'date', 'amount', 'account_id']` are identical, `desc` is different, but `desc` in one txn is a truncated or slightly changed version of the other.\n",
    "\n",
    "- FB reasons: same as above possible, but less likely. Seems more likely that they are actual duplicates created by an updating process (e.g. newer version of a txn with less redacted `desc` gets added without old version being removed, and `updated_flag` is incorrect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a082f669-668f-4dc2-9027-7b931d02f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_subset = ['user_id', 'date', 'amount', 'account_id']\n",
    "dup_var = 'dup2'\n",
    "\n",
    "df[dup_var] = df.duplicated(subset=dup_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a359a0-cb12-4cd4-bff1-eacd1fff72a8",
   "metadata": {},
   "source": [
    "### Prevalence and value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba22152-d307-48fd-a036-1642ab2285bd",
   "metadata": {},
   "source": [
    "How prevalent are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20b7d643-32bc-478e-a804-efdd59473560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 1.9% of transactions across 99% of users are potential dups.\n"
     ]
    }
   ],
   "source": [
    "n_df = len(df)\n",
    "n_dups = len(df[df[dup_var]])\n",
    "n_users_dups = df[df[dup_var]].user_id.nunique()\n",
    "n_users_df = df.user_id.nunique()\n",
    "txt = 'About {:.1%} of transactions across {:.0%} of users are potential dups.'\n",
    "print(txt.format(n_dups / n_df, n_users_dups / n_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5a50-197c-4c8a-a372-b41991168e55",
   "metadata": {},
   "source": [
    "Gross value of duplicated txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1115bb34-05f8-4c4d-8843-49d3805b7f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       424.00\n",
       "mean       2497.45\n",
       "std        8311.57\n",
       "min           3.00\n",
       "1%           11.08\n",
       "5%           48.28\n",
       "10%         104.04\n",
       "25%         298.47\n",
       "50%         880.35\n",
       "75%        2097.92\n",
       "90%        4584.54\n",
       "95%        6842.71\n",
       "99%       25811.31\n",
       "max      106598.39\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gross_value = df[df[dup_var]].set_index('user_id').amount.abs().groupby('user_id').sum()\n",
    "distr(gross_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf238fc0-691c-4f7a-b614-f7ca2fb66434",
   "metadata": {},
   "source": [
    "Most frequent txns description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6390e1fc-d595-447c-9d4e-4fd4e912e13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdbremoved>                       674\n",
       "daily od fee                       326\n",
       "tfl travel ch     tfl.gov.uk/cp    225\n",
       "tfl.gov.uk/cp     tfl travel ch    211\n",
       "<mdbremoved>                       210\n",
       "<mdbremoved> atm                   160\n",
       "daily od fee chg                   133\n",
       "islands news      london           127\n",
       "<mdbremoved> - s/o                  97\n",
       "gardens food and wlondon            87\n",
       "Name: desc, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].desc.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de08a58-1f1b-4555-9907-815d3656d69c",
   "metadata": {},
   "source": [
    "Most frequent auto tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ced6a21-b289-489c-8b6d-43282c0b3381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                           4634\n",
       "cash                          2895\n",
       "transfers                     2739\n",
       "bank charges                  2310\n",
       "food, groceries, household    1542\n",
       "public transport              1253\n",
       "gambling                      1110\n",
       "enjoyment                     1078\n",
       "lunch or snacks                652\n",
       "dining or going out            506\n",
       "Name: tag_auto, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[dup_var]].tag_auto.value_counts(dropna=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fd826-17ea-41a0-a136-b6c981de2268",
   "metadata": {},
   "source": [
    "Proportion of txns per auto tag that are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36a8dc3a-55ea-4e83-8445-ccc2371fbec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repayments            0.303867\n",
       "legal                 0.175299\n",
       "saving (general)      0.125000\n",
       "vet                   0.104603\n",
       "investment - other    0.102564\n",
       "gambling              0.094977\n",
       "media bundle          0.088889\n",
       "bank charges          0.078101\n",
       "social club           0.076923\n",
       "isa                   0.066845\n",
       "Name: tag_auto, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txns_per_tag_overall = df.tag_auto.value_counts(dropna=False)\n",
    "txns_per_tag_duplicated = df[df[dup_var]].tag_auto.value_counts(dropna=False) \n",
    "p_dup_per_tag = (txns_per_tag_duplicated / txns_per_tag_overall)\n",
    "p_dup_per_tag.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756ed25-3507-4cf7-a8dc-b67b794c00bf",
   "metadata": {},
   "source": [
    "### Inspect dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf968b26-19b6-4f9d-bbab-29ba2d89bf69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "      <th>dup1</th>\n",
       "      <th>dup2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74671</th>\n",
       "      <td>527461874</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>35177</td>\n",
       "      <td>20.0</td>\n",
       "      <td>cash notemac mar22 - one click se@xx:xx - atm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spend</td>\n",
       "      <td>other_spend</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx 0</td>\n",
       "      <td>2014-02-14</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>724235</td>\n",
       "      <td>2020-08-14 20:59:00</td>\n",
       "      <td>hsbc</td>\n",
       "      <td>current</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>True</td>\n",
       "      <td>844.299988</td>\n",
       "      <td>personal</td>\n",
       "      <td>cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cash</td>\n",
       "      <td>u</td>\n",
       "      <td>201903</td>\n",
       "      <td>200.301453</td>\n",
       "      <td>79785.007812</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74673</th>\n",
       "      <td>806078460</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>35177</td>\n",
       "      <td>20.0</td>\n",
       "      <td>&lt;mdbremoved&gt; atm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spend</td>\n",
       "      <td>other_spend</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx 0</td>\n",
       "      <td>2014-02-14</td>\n",
       "      <td>20k to 30k</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>724235</td>\n",
       "      <td>2020-08-14 20:59:00</td>\n",
       "      <td>hsbc</td>\n",
       "      <td>current</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>844.299988</td>\n",
       "      <td>personal</td>\n",
       "      <td>cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cash</td>\n",
       "      <td>c</td>\n",
       "      <td>201903</td>\n",
       "      <td>200.301453</td>\n",
       "      <td>79785.007812</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607714</th>\n",
       "      <td>191201530</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>373777</td>\n",
       "      <td>50.0</td>\n",
       "      <td>cash withdrawal at note machine atm morley service, leeds,50.00 gbp , on xx-xx-2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spend</td>\n",
       "      <td>other_spend</td>\n",
       "      <td>False</td>\n",
       "      <td>ls27 8</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>680911</td>\n",
       "      <td>2017-06-28 22:55:00</td>\n",
       "      <td>santander</td>\n",
       "      <td>current</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>personal</td>\n",
       "      <td>cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cash</td>\n",
       "      <td>u</td>\n",
       "      <td>201701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29253.576563</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607716</th>\n",
       "      <td>191201527</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>373777</td>\n",
       "      <td>50.0</td>\n",
       "      <td>direct debit payment to h3g ref xxxxxxxxxxxxxx0117, mandate no 0013</td>\n",
       "      <td>hutchison 3g</td>\n",
       "      <td>spend</td>\n",
       "      <td>communication</td>\n",
       "      <td>False</td>\n",
       "      <td>ls27 8</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>680911</td>\n",
       "      <td>2017-06-28 22:55:00</td>\n",
       "      <td>santander</td>\n",
       "      <td>current</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hutchison 3g</td>\n",
       "      <td>mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mobile</td>\n",
       "      <td>c</td>\n",
       "      <td>201701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29253.576563</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607718</th>\n",
       "      <td>191201533</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>373777</td>\n",
       "      <td>50.0</td>\n",
       "      <td>direct debit payment to h3g ref xxxxxxxxxxxxxx0117, mandate no 0003</td>\n",
       "      <td>hutchison 3g</td>\n",
       "      <td>spend</td>\n",
       "      <td>communication</td>\n",
       "      <td>False</td>\n",
       "      <td>ls27 8</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>680911</td>\n",
       "      <td>2017-06-28 22:55:00</td>\n",
       "      <td>santander</td>\n",
       "      <td>current</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hutchison 3g</td>\n",
       "      <td>mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mobile</td>\n",
       "      <td>c</td>\n",
       "      <td>201701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29253.576563</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>12750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       date  user_id  amount  \\\n",
       "74671   527461874 2019-03-22    35177    20.0   \n",
       "74673   806078460 2019-03-22    35177    20.0   \n",
       "607714  191201530 2017-01-30   373777    50.0   \n",
       "607716  191201527 2017-01-30   373777    50.0   \n",
       "607718  191201533 2017-01-30   373777    50.0   \n",
       "\n",
       "                                                                                       desc  \\\n",
       "74671                                         cash notemac mar22 - one click se@xx:xx - atm   \n",
       "74673                                                                      <mdbremoved> atm   \n",
       "607714  cash withdrawal at note machine atm morley service, leeds,50.00 gbp , on xx-xx-2017   \n",
       "607716                  direct debit payment to h3g ref xxxxxxxxxxxxxx0117, mandate no 0013   \n",
       "607718                  direct debit payment to h3g ref xxxxxxxxxxxxxx0117, mandate no 0003   \n",
       "\n",
       "            merchant tag_group            tag user_female user_postcode  \\\n",
       "74671            NaN     spend    other_spend       False        xxxx 0   \n",
       "74673            NaN     spend    other_spend       False        xxxx 0   \n",
       "607714           NaN     spend    other_spend       False        ls27 8   \n",
       "607716  hutchison 3g     spend  communication       False        ls27 8   \n",
       "607718  hutchison 3g     spend  communication       False        ls27 8   \n",
       "\n",
       "       user_registration_date user_salary_range  user_yob account_created  \\\n",
       "74671              2014-02-14        20k to 30k    1990.0      2017-05-25   \n",
       "74673              2014-02-14        20k to 30k    1990.0      2017-05-25   \n",
       "607714             2017-03-07               NaN    1963.0      2017-03-07   \n",
       "607716             2017-03-07               NaN    1963.0      2017-03-07   \n",
       "607718             2017-03-07               NaN    1963.0      2017-03-07   \n",
       "\n",
       "        account_id account_last_refreshed account_provider account_type  \\\n",
       "74671       724235    2020-08-14 20:59:00             hsbc      current   \n",
       "74673       724235    2020-08-14 20:59:00             hsbc      current   \n",
       "607714      680911    2017-06-28 22:55:00        santander      current   \n",
       "607716      680911    2017-06-28 22:55:00        santander      current   \n",
       "607718      680911    2017-06-28 22:55:00        santander      current   \n",
       "\n",
       "       data_warehouse_date_created data_warehouse_date_last_updated  debit  \\\n",
       "74671                   2019-03-23                       2019-05-06   True   \n",
       "74673                   2020-08-12                       1900-01-01   True   \n",
       "607714                  2017-03-08                       2017-10-23   True   \n",
       "607716                  2017-03-08                       1900-01-01   True   \n",
       "607718                  2017-03-08                       1900-01-01   True   \n",
       "\n",
       "        latest_balance merchant_business_line tag_auto tag_manual  tag_up  \\\n",
       "74671       844.299988               personal     cash        NaN    cash   \n",
       "74673       844.299988               personal     cash        NaN    cash   \n",
       "607714             NaN               personal     cash        NaN    cash   \n",
       "607716             NaN           hutchison 3g   mobile        NaN  mobile   \n",
       "607718             NaN           hutchison 3g   mobile        NaN  mobile   \n",
       "\n",
       "       updated_flag      ym     balance        income  savings   dup1   dup2  \\\n",
       "74671             u  201903  200.301453  79785.007812    False  False  False   \n",
       "74673             c  201903  200.301453  79785.007812    False  False   True   \n",
       "607714            u  201701         NaN  29253.576563    False  False  False   \n",
       "607716            c  201701         NaN  29253.576563    False  False   True   \n",
       "607718            c  201701         NaN  29253.576563    False  False   True   \n",
       "\n",
       "        group  \n",
       "74671    1756  \n",
       "74673    1756  \n",
       "607714  12750  \n",
       "607716  12750  \n",
       "607718  12750  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_txn_sample(df, dup_subset, n=2, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37d362-466b-464d-be7b-3ad29d434c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b972b8-83ac-4a5f-affc-df2104940aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b463b-4fe7-403b-82f7-4112d9a3c348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "baa07fe7-81e2-4f27-89d8-54ace9c98447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import functools\n",
    "import collections\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "DescAndId = collections.namedtuple('DescAndID', ['desc', 'id'])\n",
    "longest_first = functools.partial(sorted, key=lambda x: len(x.desc), reverse=True)\n",
    "\n",
    "def similarity_score(group):\n",
    "    \"\"\"Return similarity score between longest string in group and all others.\"\"\"\n",
    "    cols = list(group.columns)\n",
    "    group['score_difflib'] = np.nan\n",
    "    group['score_fuzz'] = np.nan\n",
    "    items = [DescAndId(*item) for item in zip(group.desc, group.id)]\n",
    "    longest, *others = longest_first(items)\n",
    "    for o in others:\n",
    "        group.loc[group.id == o.id, 'score_difflib'] = difflib.SequenceMatcher(None, longest.desc, o.desc).ratio()\n",
    "        group.loc[group.id == o.id, 'score_fuzz'] = fuzz.partial_ratio(longest.desc, o.desc)\n",
    "    return group[['score_difflib', 'score_fuzz'] + cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94c3cad8-89be-47c4-8d00-43f814d157d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_difflib</th>\n",
       "      <th>score_fuzz</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>desc</th>\n",
       "      <th>merchant</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_female</th>\n",
       "      <th>user_postcode</th>\n",
       "      <th>user_registration_date</th>\n",
       "      <th>user_salary_range</th>\n",
       "      <th>user_yob</th>\n",
       "      <th>account_created</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_last_refreshed</th>\n",
       "      <th>account_provider</th>\n",
       "      <th>account_type</th>\n",
       "      <th>data_warehouse_date_created</th>\n",
       "      <th>data_warehouse_date_last_updated</th>\n",
       "      <th>debit</th>\n",
       "      <th>latest_balance</th>\n",
       "      <th>merchant_business_line</th>\n",
       "      <th>tag_auto</th>\n",
       "      <th>tag_manual</th>\n",
       "      <th>tag_up</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>ym</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>savings</th>\n",
       "      <th>dup1</th>\n",
       "      <th>dup2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>918495</th>\n",
       "      <td>0.653061</td>\n",
       "      <td>67.0</td>\n",
       "      <td>558421618</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>490277</td>\n",
       "      <td>3.0</td>\n",
       "      <td>waitrose 732 cd 6728 deb</td>\n",
       "      <td>waitrose</td>\n",
       "      <td>spend</td>\n",
       "      <td>household</td>\n",
       "      <td>True</td>\n",
       "      <td>n16 6</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>1188710</td>\n",
       "      <td>2020-03-09 21:08:00</td>\n",
       "      <td>lloyds bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>473.660004</td>\n",
       "      <td>waitrose</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food, groceries, household</td>\n",
       "      <td>c</td>\n",
       "      <td>201905</td>\n",
       "      <td>962.689209</td>\n",
       "      <td>17570.730469</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>558421619</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>490277</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tfl travel ch cd 6728 deb</td>\n",
       "      <td>tfl</td>\n",
       "      <td>spend</td>\n",
       "      <td>travel</td>\n",
       "      <td>True</td>\n",
       "      <td>n16 6</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>1188710</td>\n",
       "      <td>2020-03-09 21:08:00</td>\n",
       "      <td>lloyds bank</td>\n",
       "      <td>current</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>473.660004</td>\n",
       "      <td>tfl</td>\n",
       "      <td>public transport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public transport</td>\n",
       "      <td>c</td>\n",
       "      <td>201905</td>\n",
       "      <td>962.689209</td>\n",
       "      <td>17570.730469</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>17125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score_difflib  score_fuzz         id       date  user_id  amount  \\\n",
       "918495       0.653061        67.0  558421618 2019-05-29   490277     3.0   \n",
       "918496            NaN         NaN  558421619 2019-05-29   490277     3.0   \n",
       "\n",
       "                             desc  merchant tag_group        tag user_female  \\\n",
       "918495   waitrose 732 cd 6728 deb  waitrose     spend  household        True   \n",
       "918496  tfl travel ch cd 6728 deb       tfl     spend     travel        True   \n",
       "\n",
       "       user_postcode user_registration_date user_salary_range  user_yob  \\\n",
       "918495         n16 6             2019-02-11               NaN    1992.0   \n",
       "918496         n16 6             2019-02-11               NaN    1992.0   \n",
       "\n",
       "       account_created  account_id account_last_refreshed account_provider  \\\n",
       "918495      2019-02-11     1188710    2020-03-09 21:08:00      lloyds bank   \n",
       "918496      2019-02-11     1188710    2020-03-09 21:08:00      lloyds bank   \n",
       "\n",
       "       account_type data_warehouse_date_created  \\\n",
       "918495      current                  2019-05-30   \n",
       "918496      current                  2019-05-30   \n",
       "\n",
       "       data_warehouse_date_last_updated  debit  latest_balance  \\\n",
       "918495                       1900-01-01   True      473.660004   \n",
       "918496                       1900-01-01   True      473.660004   \n",
       "\n",
       "       merchant_business_line                    tag_auto tag_manual  \\\n",
       "918495               waitrose  food, groceries, household        NaN   \n",
       "918496                    tfl            public transport        NaN   \n",
       "\n",
       "                            tag_up updated_flag      ym     balance  \\\n",
       "918495  food, groceries, household            c  201905  962.689209   \n",
       "918496            public transport            c  201905  962.689209   \n",
       "\n",
       "              income  savings   dup1   dup2  group  \n",
       "918495  17570.730469    False  False  False  17125  \n",
       "918496  17570.730469    False  False   True  17125  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = dup_txn_sample(df, dup_subset, n=1, seed=None).groupby('group').apply(similarity_score)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922b37b-0c87-47d3-97bd-42aff26a3f4b",
   "metadata": {},
   "source": [
    "- lowest same: .82 most, 72\n",
    "- highest different: .71\n",
    "\n",
    "Cases for decision:\n",
    "- One mdbremoved, the other unremoved has very low score -> treat as dup or not? (could use 100 fuzz score to exclude)\n",
    "- daily od fee _date_ only differs in date and has very high score but is different - exclude manually or handle automatically. some other descs that contain differing dates. could match dates and ensure they differ\n",
    "- remove `-`, `)` and `(`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f21a9e5e-63e0-4452-a740-5ea364a556c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method StringMethods.normalize of <pandas.core.strings.accessor.StringMethods object at 0x17c3c1490>>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.desc.str.strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eba16ec5-bf0d-4742-926b-fe635ee844e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_subset = ['user_id', 'date', 'amount', 'account_id']\n",
    "dup_var = 'dup2'\n",
    "df[dup_var] = df.duplicated(subset=dup_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ecf876dc-c92c-4634-8180-cc2976e4e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lnk sk store, 44/4 cd 8050 12jul15\n",
      "   sby tamworth cd 8050 13jul15\n",
      "   68\n",
      "\n",
      "lnk sk store, 44/4 cd 8050 13dec15\n",
      "   lnk star news coto cd 9447 12dec15\n",
      "   59\n",
      "\n",
      "the boathouse bras cd 4720 deb\n",
      "   tesco stores 6711 cd 4720 deb\n",
      "   62\n",
      "\n",
      "<mdbremoved>\n",
      "   <mdbremoved>\n",
      "   100\n",
      "\n",
      "   <mdbremoved>\n",
      "   100\n",
      "\n",
      "<mdbremoved> xxxxxx xxxx5560\n",
      "   <mdbremoved>\n",
      "   100\n",
      "\n",
      "bank credit <mdbremoved>\n",
      "   bank credit <mdbremoved>\n",
      "   100\n",
      "\n",
      "xxxxxx xxxx0290 internet transfer\n",
      "   xxxxxx xxxx8658 internet transfer\n",
      "   88\n",
      "\n",
      "32 red cd 7512 deb\n",
      "   32 red cd 7512 deb\n",
      "   100\n",
      "\n",
      "non-stg purch fee cd 6710 deb\n",
      "   non-stg purch fee cd 6710 deb\n",
      "   100\n",
      "\n",
      "   non-stg purch fee cd 6710 deb\n",
      "   100\n",
      "\n",
      "   non-stg purch fee cd 6710 deb\n",
      "   100\n",
      "\n",
      "card payment to iz *canopy market,2.00 gbp, rate 1.00/gbp on 10-07-2020\n",
      "   card payment to iz *crosstown,2.00 gbp, rate 1.00/gbp on 10-07-2020\n",
      "   85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from functools import partial\n",
    "\n",
    "longest_first = partial(sorted, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "for idx, data in dd.groupby('group'):\n",
    "    longest, *others = longest_first(data.desc.values)\n",
    "    print(longest)\n",
    "    for other in others:\n",
    "        print('   {}'.format(other))\n",
    "        print('   {}'.format(fuzz.partial_ratio(longest, other)), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18c705-cc67-4229-b3ce-79780ff0d9ed",
   "metadata": {},
   "source": [
    "## Type 1 dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13f683-408a-47a2-92cb-8857b97c8f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entropy",
   "language": "python",
   "name": "entropy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
